{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuCqg_by2--1"
      },
      "source": [
        "#Machine learning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lAWOoOkK73R"
      },
      "source": [
        "Dado que se está trabajando en un entorno en la nube, se procede a enlazar el cuaderno con el repositorio donde se encuentran alojados los datos que van a ser tratados en el problema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2J2M7WE6rfa",
        "outputId": "bfe9fb7e-b47a-455a-e8ff-b28df1255ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kqH5pT-L92l"
      },
      "source": [
        "Se importan las librerías necesarias para poder realizar tanto el tratamiento de los datos, como el preprocesamiento de los mismos. Además, se importan las librerías necesarias para entrenar y evaluar los modelos con los cuales se va a tratar de solucionar el problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC8Vwd9x09tV",
        "outputId": "fe8df188-7e40-4715-97ef-a9136e5f55d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from glob import glob\n",
        "import numpy as np #se importa numpy para realizar el tratamiento de arrays numéricos\n",
        "\n",
        "import os #librería usada para crear directorios dentro del sistema.\n",
        "import sys\n",
        "import pandas as pd #Librería usada para leer y escribir las bases de datos en formato .csv\n",
        "from sklearn.preprocessing import StandardScaler #normalizador standard de sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler #normalizador alternativo de sklearn\n",
        "from sklearn.decomposition import PCA #Herramienta para realizar análisis de componentes principales\n",
        "import sklearn.neural_network as neural #herramienta para la creación de redes neuronales de sklearn\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "#import pyedflib as pyedf #librería necesaria para tratar datos .edf\n",
        "import matplotlib.pyplot as ptl\n",
        "from sklearn.utils import class_weight #herramienta de sklearn para determinar los pesos de cada clase en un problema desbalanceado\n",
        "\n",
        "from keras.layers import Dense, Flatten, Conv1D,Dropout,MaxPooling1D #se importan las librerías necesarias para crear una red neuronal con capas convolucionales de 1d y capas de pooling\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder #Herramienta para realizar el one hot encoding de las etiquetas.\n",
        "from keras.models import Sequential #Herramienta que permite la creación de redes neuronales repartidas en capas.\n",
        "\n",
        "from keras.regularizers import l1 #Herramienta de keras para entrenar un modelo con regularizaciíon L1\n",
        "from keras import optimizers #Optimizadores de Keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY34jPYEIQ_h"
      },
      "source": [
        "#Tratamiento de los datos crudos\n",
        "\n",
        "En esta sección se trata de crear la base de datos en formato .csv (descriptores y etiquetas)a partir de los datos de las señales que se encuentran en formato .edf.\n",
        "\n",
        "Dado que el sistema final recibirá un segmento de 30 segundos de una señal cerebral, los datos de cada una de las señales, las cuales tienen duración variable, se dividirán en segmentos de 30 segundos de duración al que se asignará una etiqueta basandose en el estado de sueño predominante en esos 30 segundos. Es decir, el problema a tratar se transforma de esta manera en un problema multiclase con 1 sola etiqueta por dato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT9w6EiV2kIn"
      },
      "source": [
        "dataset=\"/content/drive/My Drive/parcial2/sleep-cassette\"\n",
        "archivos= sorted(glob(os.path.join(dataset, \"*.edf\"))) #se cargan los datos del dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCirVHmXNuTH"
      },
      "source": [
        "El método generar etiquetas permite crear las eiquetas de n señales de duración 30 segundos basandose en el archivo de etiquetas creado para toda la duración de esa señal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g65gjz3Y2yBU"
      },
      "source": [
        "def generar_etiquetas(archivo):\n",
        "  st_FileHypEdf = pyedf.EdfReader(archivo) #se lee el archivo que contiene las etiquetas del problema\n",
        "  v_HypTime, v_HypDur, v_Hyp = st_FileHypEdf.readAnnotations() #se determinan los arrays de tiempos de inicio de cada etiqueta, su tiempo de duración y su valor\n",
        "\n",
        "  largo = sum(v_HypDur)/30 #se encuentra el número de etiquetas de salida\n",
        "  tiempoResiduo = 0\n",
        "  etiquetas = [] #array donde se van a almacenar las etiquetas creadas\n",
        "  tiempoDuracion2 = 0\n",
        "  for i in range(1,v_HypTime.shape[0]-2):\n",
        "    etiquetaActual = v_Hyp[i] #se calcula la etiqueta actual para el segmento de tiempo en el que nos encontramos\n",
        "    tiempoDuracion = v_HypDur[i] #duración de la etiqueta\n",
        "    numeroEtiquetas = tiempoDuracion//30 #el número de etiquetas es la división entera del tiempo de duración (en segundos) y 30 segundos\n",
        "    tiempoResiduo = tiempoDuracion%30 #el tiempo residuo se usa para calcular la siguiente etiqueta\n",
        "    for j in range(int(numeroEtiquetas)): #se crean tantas etiquetas como las que fueron calculadas\n",
        "      etiquetas.append(etiquetaActual)\n",
        "    tiempoDuracion2 = tiempoDuracion2+numeroEtiquetas #se actualiza el tiempo de duración\n",
        "\n",
        "  return etiquetas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlSO8h1GT_mB"
      },
      "source": [
        "Se usa el método creado anteriormente para calcular las etiquetas de cada uno de los archivos edf presentes en la base de datos cruda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "fc402390-9b6c-4c87-964d-8561086bf574",
        "id": "FqCByil0T80B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resultados= dict() #diccionario donde se van a almacenar las etiquetas de cada clase.\n",
        "k=0 #indicador del número de archivo.\n",
        "for i in range(0,212,2): #solo se exploran los archivos de etiquetas, se ignoran los archivos de la señal de sueño.\n",
        "  resultados['resultado'+str(k)]=generar_etiquetas(archivos[i+1]) # se almacenan en un diccionario cada una de las etiquetas\n",
        "  print(np.array(resultados['resultado'+str(k)]).shape) # se imprime el largo de cada uno de los diccionarios.\n",
        "  k=k+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(721,)\n",
            "(1008,)\n",
            "(983,)\n",
            "(1066,)\n",
            "(905,)\n",
            "(890,)\n",
            "(832,)\n",
            "(791,)\n",
            "(1116,)\n",
            "(1084,)\n",
            "(552,)\n",
            "(1128,)\n",
            "(723,)\n",
            "(896,)\n",
            "(856,)\n",
            "(1153,)\n",
            "(1014,)\n",
            "(934,)\n",
            "(1023,)\n",
            "(1960,)\n",
            "(985,)\n",
            "(973,)\n",
            "(809,)\n",
            "(682,)\n",
            "(1725,)\n",
            "(857,)\n",
            "(908,)\n",
            "(884,)\n",
            "(832,)\n",
            "(836,)\n",
            "(1647,)\n",
            "(1029,)\n",
            "(885,)\n",
            "(883,)\n",
            "(1657,)\n",
            "(844,)\n",
            "(800,)\n",
            "(1415,)\n",
            "(1159,)\n",
            "(903,)\n",
            "(901,)\n",
            "(1463,)\n",
            "(688,)\n",
            "(979,)\n",
            "(988,)\n",
            "(787,)\n",
            "(1614,)\n",
            "(1555,)\n",
            "(1655,)\n",
            "(852,)\n",
            "(901,)\n",
            "(1477,)\n",
            "(860,)\n",
            "(932,)\n",
            "(970,)\n",
            "(1007,)\n",
            "(950,)\n",
            "(1011,)\n",
            "(1488,)\n",
            "(811,)\n",
            "(734,)\n",
            "(934,)\n",
            "(1061,)\n",
            "(1441,)\n",
            "(901,)\n",
            "(1769,)\n",
            "(1194,)\n",
            "(1381,)\n",
            "(1462,)\n",
            "(856,)\n",
            "(845,)\n",
            "(704,)\n",
            "(798,)\n",
            "(1389,)\n",
            "(1656,)\n",
            "(1751,)\n",
            "(944,)\n",
            "(952,)\n",
            "(958,)\n",
            "(804,)\n",
            "(665,)\n",
            "(764,)\n",
            "(579,)\n",
            "(842,)\n",
            "(1075,)\n",
            "(972,)\n",
            "(1088,)\n",
            "(1046,)\n",
            "(864,)\n",
            "(904,)\n",
            "(1068,)\n",
            "(2056,)\n",
            "(1938,)\n",
            "(1787,)\n",
            "(981,)\n",
            "(921,)\n",
            "(1206,)\n",
            "(983,)\n",
            "(967,)\n",
            "(834,)\n",
            "(877,)\n",
            "(976,)\n",
            "(936,)\n",
            "(1597,)\n",
            "(1028,)\n",
            "(927,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74LjqqvzUaZt"
      },
      "source": [
        "Se concatenan los arrays creados con el fin de hacer un archivo general de etiquetas de cada uno de los archivos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nozsux7m4Bie",
        "outputId": "c9918e93-646d-48c5-ba4d-547e9d3778d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final2=np.concatenate((np.array(resultados['resultado'+str(0)]), np.array(resultados['resultado'+str(1)])), axis=0)\n",
        "for k in range(2,106):\n",
        "  print(k)\n",
        "  final2=np.concatenate((final2, np.array(resultados['resultado'+str(k)])), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-G2KGOLUzTa"
      },
      "source": [
        "Se crea un archivo final de etiquetas en el que se organizan en 4 clases correspondientes a las especificadas en la descripción del examen 2. De este modo se agrupan las etiquetas en los números 0,1,2,3 lo cual facilitará su tratamiento más adelante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPsMaJPf6Glh"
      },
      "source": [
        "for i in range(final2.shape[0]):\n",
        "  if final2[i]=='Sleep stage W': #datos de la clase 0\n",
        "    final2[i]=0\n",
        "  elif final2[i]=='Sleep stage 1' or final2[i]=='Sleep stage 2': #datos de la clase 1\n",
        "    final2[i]=1\n",
        "  elif final2[i]=='Sleep stage 3' or final2[i]=='Sleep stage 4': #datos de la clase 2\n",
        "    final2[i]=2\n",
        "  elif final2[i]=='Sleep stage R': #datos de la clase 3\n",
        "    final2[i]=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sYRcHg8XVBV"
      },
      "source": [
        "Se almacena el array creado en un archivo .csv lo cual era el objetivo principal del proceso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPG98sbrXUDC"
      },
      "source": [
        "pd.DataFrame(final2).to_csv('/content/drive/My Drive/parcial2/y_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSmfHUvnixmt"
      },
      "source": [
        "El método guardar_señal permite dividir un archivo de datos edf de la señal del encefalograma en segmentos de 30 segundos a la velocidad de muestréo definida para dicha señal (0.01 muetras/s). esto implica que cada segmento de 30 segundos de señal contiene 3000 muestras.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BamsdpG5tyz"
      },
      "source": [
        "def guardar_señal(archivo,etiqueta):\n",
        "  st_FileHypEdf = pyedf.EdfReader(etiqueta)\n",
        "\n",
        "  v_HypTime, v_HypDur, v_Hyp = st_FileHypEdf.readAnnotations() #se leen los datos de la señal\n",
        "\n",
        "\n",
        "\n",
        "  st_FileEdf = pyedf.EdfReader(archivo)\n",
        "  # Lectura de las señales s_SigNum señales con nombres v_Signal_Labels\n",
        "\n",
        "  s_SigNum = st_FileEdf.signals_in_file\n",
        "  #print(s_SigNum)\n",
        "  v_Signal_Labels = st_FileEdf.getSignalLabels()\n",
        "\n",
        "\n",
        "  # Conversion a segundos usando frecuencia de muestreo.\n",
        "  s_SigRef = 0\n",
        "  s_NSamples = st_FileEdf.getNSamples()[0]\n",
        "  s_FsHz = st_FileEdf.getSampleFrequency(s_SigRef)\n",
        "  print(s_NSamples)\n",
        "\n",
        "  # v_Sig = np.zeros((s_NSamples, 1))\n",
        "  v_Sig = st_FileEdf.readSignal(s_SigRef)\n",
        "  v_Time = np.arange(0, s_NSamples) / s_FsHz\n",
        "\n",
        "  señales=[] #array donde van a ser almacenados los segmentos de la señal\n",
        "  señal=int(v_HypTime[1]*100)\n",
        "  for i in range(int((v_HypTime[int(v_HypTime.shape[0]-1)]-v_HypDur[int(v_HypTime.shape[0]-2)]-v_HypDur[0])/30)):\n",
        "    señales.append(v_Sig[señal:señal+3000]) #se almacena la señal cada 30 segundos en un array\n",
        "    señal=señal+3000 #se actualiza el tiempo hasta el que se ha segmentado la señal\n",
        "  return señales\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlHaCyY5mKAi"
      },
      "source": [
        "A continuación se recorren todos los archivos de señales y se divide cada uno en los intervalos deseados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSnNVdoq5-S7",
        "outputId": "c96a6219-9135-42d1-f5d9-f6678f370225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resultados= dict() #diccionario creado para almacenar los segmentos de cada archivo de la base de datos\n",
        "k=0 #contador de archivos\n",
        "for i in range(0,212,2):\n",
        "  resultados['resultado'+str(k)]=guardar_señal(archivos[i],archivos[i+1]) #se almacenan los segmentos para cada uno de los archivos\n",
        "  print(np.array(resultados['resultado'+str(k)]).shape)\n",
        "  k=k+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7950000\n",
            "(721, 3000)\n",
            "8490000\n",
            "(1008, 3000)\n",
            "8406000\n",
            "(983, 3000)\n",
            "8550000\n",
            "(1066, 3000)\n",
            "8412000\n",
            "(905, 3000)\n",
            "8268000\n",
            "(890, 3000)\n",
            "8460000\n",
            "(832, 3000)\n",
            "8196000\n",
            "(791, 3000)\n",
            "7710000\n",
            "(1116, 3000)\n",
            "8376000\n",
            "(1084, 3000)\n",
            "8166000\n",
            "(552, 3000)\n",
            "8418000\n",
            "(1128, 3000)\n",
            "8310000\n",
            "(723, 3000)\n",
            "8490000\n",
            "(896, 3000)\n",
            "8430000\n",
            "(856, 3000)\n",
            "8310000\n",
            "(1153, 3000)\n",
            "8388000\n",
            "(1014, 3000)\n",
            "7902000\n",
            "(934, 3000)\n",
            "8196000\n",
            "(1023, 3000)\n",
            "8574000\n",
            "(1960, 3000)\n",
            "8160000\n",
            "(985, 3000)\n",
            "8574000\n",
            "(973, 3000)\n",
            "7926000\n",
            "(809, 3000)\n",
            "8340000\n",
            "(682, 3000)\n",
            "8358000\n",
            "(1725, 3000)\n",
            "7818000\n",
            "(857, 3000)\n",
            "8442000\n",
            "(908, 3000)\n",
            "8268000\n",
            "(884, 3000)\n",
            "8322000\n",
            "(832, 3000)\n",
            "7860000\n",
            "(836, 3000)\n",
            "8592000\n",
            "(1647, 3000)\n",
            "7878000\n",
            "(1029, 3000)\n",
            "8256000\n",
            "(885, 3000)\n",
            "8226000\n",
            "(883, 3000)\n",
            "8172000\n",
            "(1657, 3000)\n",
            "8268000\n",
            "(844, 3000)\n",
            "8526000\n",
            "(800, 3000)\n",
            "8322000\n",
            "(1415, 3000)\n",
            "7830000\n",
            "(1159, 3000)\n",
            "8412000\n",
            "(903, 3000)\n",
            "8010000\n",
            "(901, 3000)\n",
            "8430000\n",
            "(1463, 3000)\n",
            "8082000\n",
            "(688, 3000)\n",
            "8100000\n",
            "(979, 3000)\n",
            "8280000\n",
            "(988, 3000)\n",
            "8238000\n",
            "(787, 3000)\n",
            "7920000\n",
            "(1614, 3000)\n",
            "8106000\n",
            "(1555, 3000)\n",
            "8130000\n",
            "(1655, 3000)\n",
            "8280000\n",
            "(852, 3000)\n",
            "7998000\n",
            "(901, 3000)\n",
            "8400000\n",
            "(1477, 3000)\n",
            "8160000\n",
            "(860, 3000)\n",
            "7320000\n",
            "(932, 3000)\n",
            "8610000\n",
            "(970, 3000)\n",
            "8364000\n",
            "(1007, 3000)\n",
            "8442000\n",
            "(950, 3000)\n",
            "8268000\n",
            "(1011, 3000)\n",
            "8430000\n",
            "(1488, 3000)\n",
            "7938000\n",
            "(811, 3000)\n",
            "8424000\n",
            "(734, 3000)\n",
            "8010000\n",
            "(934, 3000)\n",
            "8100000\n",
            "(1061, 3000)\n",
            "8070000\n",
            "(1441, 3000)\n",
            "7848000\n",
            "(901, 3000)\n",
            "8430000\n",
            "(1769, 3000)\n",
            "8280000\n",
            "(1194, 3000)\n",
            "8250000\n",
            "(1381, 3000)\n",
            "8370000\n",
            "(1462, 3000)\n",
            "8130000\n",
            "(856, 3000)\n",
            "7596000\n",
            "(845, 3000)\n",
            "6798000\n",
            "(704, 3000)\n",
            "8550000\n",
            "(798, 3000)\n",
            "8520000\n",
            "(1389, 3000)\n",
            "8250000\n",
            "(1656, 3000)\n",
            "8310000\n",
            "(1751, 3000)\n",
            "7890000\n",
            "(944, 3000)\n",
            "8370000\n",
            "(952, 3000)\n",
            "8184000\n",
            "(958, 3000)\n",
            "8574000\n",
            "(804, 3000)\n",
            "8292000\n",
            "(665, 3000)\n",
            "8046000\n",
            "(764, 3000)\n",
            "8430000\n",
            "(579, 3000)\n",
            "8340000\n",
            "(842, 3000)\n",
            "7860000\n",
            "(1075, 3000)\n",
            "8334000\n",
            "(972, 3000)\n",
            "8370000\n",
            "(1088, 3000)\n",
            "8010000\n",
            "(1046, 3000)\n",
            "8088000\n",
            "(864, 3000)\n",
            "8568000\n",
            "(904, 3000)\n",
            "8220000\n",
            "(1068, 3000)\n",
            "8370000\n",
            "(2056, 3000)\n",
            "8640000\n",
            "(1938, 3000)\n",
            "8640000\n",
            "(1787, 3000)\n",
            "8400000\n",
            "(981, 3000)\n",
            "6408000\n",
            "(921, 3000)\n",
            "8250000\n",
            "(1206, 3000)\n",
            "8310000\n",
            "(983, 3000)\n",
            "8136000\n",
            "(967, 3000)\n",
            "8250000\n",
            "(834, 3000)\n",
            "8322000\n",
            "(877, 3000)\n",
            "7806000\n",
            "(976, 3000)\n",
            "8232000\n",
            "(936, 3000)\n",
            "8220000\n",
            "(1597, 3000)\n",
            "8040000\n",
            "(1028, 3000)\n",
            "8316000\n",
            "(927, 3000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wi9uugPTlxeJ"
      },
      "source": [
        "Se concatenan todos los diccionarios creados para cada archivo, esto con el fin de hacer un solo archivo con toda la información de las señales que coincida con el archivo creado para las etiquetas. De este modo, se tienen 2 archivos con los cuales se pueden realizar comodamente las tareas de machine learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do9FAmQYA_Yy",
        "outputId": "9c0464ed-1443-4e29-c350-52764de844a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "final=[]\n",
        "final2=np.concatenate((np.array(resultados['resultado'+str(0)]), np.array(resultados['resultado'+str(1)])), axis=0)\n",
        "for k in range(2,106):\n",
        "  print(k)\n",
        "  final2=np.concatenate((final2, np.array(resultados['resultado'+str(k)])), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlhlL2WAn6k_"
      },
      "source": [
        "Por último se guarda la información del arary en un archivo csv para poder usarla en cualquier momento del proceso de diseño sin tener que realizar todo el proceso descrito anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KnlOXfzBTWP"
      },
      "source": [
        "df = pd.DataFrame(final2) #se transforma el array en un dataframe de pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZDR94PzFCKW"
      },
      "source": [
        "df.to_csv('/content/drive/My Drive/parcial2/X1.csv') #se almacena el array en una dirección de memoria específica"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNwZSk04MrM"
      },
      "source": [
        "#LECTURA DE LA BASE DE DATOS:\n",
        "\n",
        "En primer lugar, se debe realizar la lectura de la base de datos. Para esto se usa la librería panda. Se realiza la conversión del txt a csv sin tener en cuenta la cabecera ya que la base de datos no tiene nombres de las características."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4p8s8Rg2ok2"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv (\"/content/drive/My Drive/parcial2/X.csv\",header=0) #se importan los datos de las señales"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09m_3Ban7mbN"
      },
      "source": [
        "df= df.drop('Unnamed: 0', 1) #se elimina la columna de indice producto del preprocesamiento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ0AcfsR-D_N"
      },
      "source": [
        "df2=pd.read_csv (\"/content/drive/My Drive/parcial2/y_train.csv\",header=0) #se importan las etiquetas para cada uno de los datos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "burZmds8-Yg0"
      },
      "source": [
        "df2= df2.drop('Unnamed: 0', 1) #se elimina la columna de indice producto del preprocesamiento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUQ4JD574OVE"
      },
      "source": [
        "# Pre-procesamiento\n",
        "\n",
        "Se realiza el pre-procesamiento de los datos con el fin de eliminar características y ajustar los datos para el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3LAtmtJ4RNk"
      },
      "source": [
        "##Normalizar:\n",
        "Para la normalización estandar de los datos, la cual fue usada en todo el desarrollo se tiene:\n",
        "\n",
        "*   Normalizado=(x-media)/(varianza)\n",
        "\n",
        "De esta forma se tienen los datos con media 0 y desviación estandar de 1. Esto evitara que existan datos que sean muy grandes comparados con los otros (datos atipicos) que desajusten el modelo e impidan un correcto ajuste de los parámetros a construir. \\\n",
        "\n",
        "Este proceso se realizó con la herramienta standardScaler de sklearn la cual ejecuta esta acción automáticamente. Cabe aclarar que también se probó con un normalizador alternativo, el MinMaxScaler, pero este no brindo tan buenos resultados como el normalizador standard, por lo que se eligió este último para realizar todos los procedimientos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkp7uVEe2qT9",
        "outputId": "063a9877-23c6-4a76-b944-bad8a85481db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#normalización entrada:\n",
        "x_train=df.values  # se convierte los datos a un array de numpy\n",
        "\n",
        "#normalizar\n",
        "normalizar= StandardScaler() #se crea el modelo normalizador de sklearn\n",
        "normalizar.fit(x_train) #se ajustan los parámetros de ese modelo con los datos del dataset\n",
        "x_train=normalizar.transform(x_train) #se normalizan los datos\n",
        "y_train=df2.values #se convierten las etiquetas a un array de numpy\n",
        "y_train.shape #se revisa el largo de las etiquetas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112652, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRVUZvV4VEU"
      },
      "source": [
        "##Análisis de componentes principales:\n",
        "\n",
        "Dado que de antemano no se conocen los descriptores a usar en la señal de entrada y con el fin de reducir la dimensionalidad de los datos se usa análisis de componentes principales(PCA). Esto permite eliminar variables redundantes, lo cual ayudara a prevenir el overfitting y reducir el tiempo de entrenamiento.  \n",
        "\n",
        "PCA tiene como objetivo describir un conjunto de datos en términos de nuevas variables no correlacionadas.Entonces, esta técnica busca proyectar los datos en n vectores que sean ortonormales y maximicen la varianza. En este caso se quiere reducir en gran medidad el número de variables ya que los procesos de diseño pueden tomar mucho tiempo con datos redudantes.\n",
        "\n",
        "En este caso se usó una varianza entre datos del 95% esto quiere decir que solo se acepten datos que varíen entre si por lo menos esta cantidad. Este valor fue elegído en el proceso de diseño luego de probar varios valores para este parámetro (0.6, 0.8, 0.9, 0.95) y encontrar que la precisión del modelo se maximiza con valores altos de varianza, tales como el usado en este caso."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYrNejxl2321"
      },
      "source": [
        "#Análisis de componentes principales\n",
        "pca=PCA(.95) #se crea el modelo de pca usando la herramienta de sklearn\n",
        "pca.fit(x_train) #se ajusta el modelo usando los datos del dataset\n",
        "x_train=pca.transform(x_train) #se actualizan las variables del modelo para reducir la dimensionalidad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffsKitLKsDFO"
      },
      "source": [
        "Después de aplicar PCA se redujo la dimensionalidad a 885. Esto indica que se redujeron aproximadamente el 70% de las variables iniciales con lo que se puede reducir en gran medida los tiempos de procesamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1DqI2T_6i5b",
        "outputId": "4eb0e115-66c2-4a48-9b74-a51b1d03b0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape #número de filas del array de características"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(112652, 885)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEKXEQzhsJLg"
      },
      "source": [
        "Dado que al momento de crear la base de datos no se notó el hecho de que existian 2 etiquetas que no tenían sentido para el problema, tal cual y como se planteó, estas etiquetas son: 'Movement time' y 'Sleep stage ?' por lo que en las siguientes celdas se va a tratar de eliminar los datos correspondientes a estas etiquetas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oEd3WHVaGdk"
      },
      "source": [
        "#ajustar datos\n",
        "x=np.ones((111752, 885))+10 #se crea el array donde se van a almacenar las características corregidas del problema\n",
        "y=np.ones((111752, 1))+10 #se crea el array donde se van a almacenar las etiquetas corregidas.\n",
        "\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbd4nE68fpiA"
      },
      "source": [
        "j=0\n",
        "for n in range(y_train.shape[0]): #se recorre todo el array de etiquetas\n",
        "  if y_train[n]!='Movement time' and y_train[n]!='Sleep stage ?':\n",
        "    #se almacenan si estas son diferentes de las etiquetas desconocidas\n",
        "    y[j]=y_train[n] #se actualiza el array de etiquetas\n",
        "    x[j]=x_train[n] #se actualiza el array de descriptores\n",
        "    j=j+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4mV0RF8AudV"
      },
      "source": [
        "# Estimativo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltusmurBudXE"
      },
      "source": [
        "A continuación se dividen los datos en set de entrenamiento, validación y test. En este caso se usa la convención usual para elegír que porcentaje de datos corresponden a cada set, es decir, se deja un 10% de los datos para validación, 10% para test y 80% para entrenamiento.\n",
        "\n",
        "En este caso se tienen 111752 datos por lo cual se separan 89402 para entrenamiento, 11176 para validación y 11176 datos para test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtLi93B2VyAR"
      },
      "source": [
        "X=x[0:89402]  #datos de entrenamiento\n",
        "\n",
        "Y=y[0:89402]  #datos de entrenamiento\n",
        "\n",
        "X_val=x[89402:100572]  #datos de validación\n",
        "\n",
        "Y_val=y[89402:100572]  #datos de validación\n",
        "\n",
        "X_test=x[100572:111752]  #datos de prueba\n",
        "\n",
        "Y_test=y[100572:111752]  #datos de prueba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WelBM2xixNvU"
      },
      "source": [
        "El número de datos para cada clase del problema es:\n",
        "\n",
        "clase 0: 22,820\\\n",
        "clase 1: 60,028\\\n",
        "clase 2: 10,623\\\n",
        "clase 3: 18,281\n",
        "\n",
        "por lo que se nota que no se está trabajando con un problema balanceado y es necesario trabajar este con los desbalances presentes. Para esto se usa la herramienta de sklearn class_weight y se calculan los pesos que debe tener cada clase para que se pueda entrenar el modelo adecuadamente\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoFg6IPzC_J4"
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y.ravel()),\n",
        "                                                 y.ravel()) #se calculan los pesos usando el archivo de etiquetas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AAux4Z7K4Tz",
        "outputId": "0eee837e-1c30-46a0-d379-28c1f4576dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_weights #pesos de cada clase arrojados en el paso anterior"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.22427695, 0.46541614, 2.62995387, 1.52825338])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOeTejF-7lTM"
      },
      "source": [
        "#Encontrar el modelo\n",
        "\n",
        "Con el fin de resolver el problema, se trató de crear diferentes tipos de modelos de aprendizaje, tanto en el campo del aprendizaje balanceado como en el del no balanceado. De esta forma, en el campo balanceado se trataron de entrenar 3 tipos de modelos: Suport vector machines (SVM), Adaboost y redes neuronales. Los SVM supusieron resultados aceptables con tiempos de entrenamiento demasiado altos, lo que volvía casi imposible realizar una sintonización de los parámetros de aprendizaje de este en el plazo de trabajo que se tuvo a disposición,  por lo que se terminó descartando esta solución. En sentido contrario, Adaboost supuso tiempos de entrenamiento bajos con errores altos, sin importar la sintonización de sus parámetros, por lo que fue descartada inmediatamente. Por último, las redes neuronales fueron el candidato más fuerte y permitieron obtener precisiones más altas que los métodos anteriores con tiempos de entrenamiento aceptables. Por esta razón, se evaluaron varios modelos y se llegó a resultados insuficientes, aunque mejores que el azar, por lo que se terminó descartando la solución balanceada para este problema.\n",
        "\n",
        "Una aproximación diferente al problema, antes de pasar al campo desbalanceado, fue realizar una arquitectura onevsall con redes neuronales, donde la primera clase a descartar era la clase más numerosa, en este caso aproximadamente 6 veces más numerosa que cualquier otra clase. A partir de este punto, el problema se trataba como un problema balanceado de solo 3 clases y se entrenaba basandose en los datos de solo estas 3 clases. Sin embargo, el resultado no fue mejor que el encontrado usando redes neuronales convencionales por lo que se terminó por descartar también esta solución.\n",
        "\n",
        "Por último, Se realizó una aproximación por aprendizaje no balanceado, añadiendo pesos a cada una de las clases y entrenando redes neuronales convencionales. Los resultados en este caso fueron mucho mejores que los encontrados hasta ese momento, con tiempos de entrenamiento bajos y errores igualmente bajos, por lo que se decidió elegir este modelo para solucionar el problema.\n",
        "\n",
        "A continuación se pasó a revisar diferentes aproximaciones al problema usando diferentes tipos de redes neuronales, encontrando que las redes neuronales conconvolucionales mejoraban la precisión del modelo mejor que otros tipos de redes. Despúes de realizar muchos ensayos con diferentes parámetros de las redes como son learning rate, regularización, funciones de activación y funciones de perdidas, se encontró un resultado que se cree suficiente para este problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FIkvsmv2uyr"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E69qMr4V2Uk6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxRLAGXO0-QR"
      },
      "source": [
        "svc = svm.SVC(C=30, kernel = 'rbf', verbose = False, gamma = 1/4) #se compila el SVM para un valor de C específico.\n",
        "svc.fit(X, Y) #se entrena el modelo con los datos de entrenamientos creados anteriormente.\n",
        "C=svc.score(X_val,Y_val) #se almacena en el array el valor resultante de validar el modelo en los datos de validación."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBN6JEdM1qFc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXgLSV4hkNRa"
      },
      "source": [
        "#AdaBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diUtTwSUkQD7"
      },
      "source": [
        "AdaBoost con arboles de decisión permite crear diferentes clasificadores que tratan de corregir al anterior. Es importante elegir la profundidad del arbol y el numero de estimadores que se usaran con el fin de encontrar la mejor accuracy posible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_kPAwlN2dHA"
      },
      "source": [
        "profundidad=[1,2,3] #Profundidad\n",
        "estimadores=[50,100,150,200,250,300,350,400,450,500] #cantidad de estimadores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmB5o47l2dTH"
      },
      "source": [
        "models= dict() #diccionario para guardar cada modelo\n",
        "accuracys= np.ones(30)#creacion array de unos para guardar el accuracy\n",
        "graficax= np.ones(30)#creacion array de unos para guardar el numero de stimadores\n",
        "graficay=np.ones(30)#creacion array de unos para guardar la progundidad\n",
        "j=0\n",
        "for i in estimadores:\n",
        "  for k in profundidad:\n",
        "    models['model'+str(i)+'_'+str(k)] = AdaBoostClassifier(DecisionTreeClassifier(max_depth=k),\n",
        "                         algorithm=\"SAMME\",\n",
        "                         n_estimators=i)#crear modelos\n",
        "    models['model'+str(i)+'_'+str(k)].fit(X, Y.ravel())#entrenar modelos\n",
        "    accuracys[j] =models['model'+str(i)+'_'+str(k)].score(X_val, Y_val)#evaluar\n",
        "    graficax[j]=i\n",
        "    graficay[j]=k\n",
        "    j=j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZChsPmXeyl8",
        "outputId": "16a0ee46-8664-41e1-e520-99f783b6990d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#encontrar el modelo con el mejor accuracy\n",
        "value2=np.max(accuracys)\n",
        "i2= np.where(accuracys == value2)\n",
        "\n",
        "maximo_x=graficax[i2[0][0]]\n",
        "\n",
        "maximo_y=graficay[i2[0][0]]\n",
        "print(\"Mejor modelo en los datos de test ,usando \"+str(int(maximo_x))+\" como numero de estimadores y \"+str(int(maximo_y))+\" como profundidad, con un valor  de:\"+str(value2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor modelo en los datos de test ,usando 300 como numero de estimadores y 2 como profundidad, con un valor  de:51.81021214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq-J2zYy3NDP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KZ13oH-Nnv1"
      },
      "source": [
        "##one hot encoding\n",
        "Como convención para realizar el entrenamiento de un modelo, basado en redes neuronales, se usa el \"one hot encoding\" para codificar las etiquetas de salida. Esto significa que a la salida de la red neuronal a usar se tienen tantas neuronas como clases del problema. Esto significa que cada neurona corresponde a una clase y la salida en dicha neurona solo es 1 cuando los datos correspondan a dicha clase y 0 en caso contrario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eh6urbPTepl",
        "outputId": "430cfc2f-8932-45c6-e0c8-26da1a9800fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "ohe = OneHotEncoder() #se declara el modelo de one hot encoding de sklearn\n",
        "Y = ohe.fit_transform(Y).toarray() #se ajustan las etiquetas de entrenamiento a la nueva codificación.\n",
        "Y_val = ohe.fit_transform(Y_val).toarray() #se ajustan las etiquetas de validación a la nueva codificación.\n",
        "Y_test = ohe.fit_transform(Y_test).toarray() #se ajustan las etiquetas de test a la nueva codificación"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrdxfY6d15n8"
      },
      "source": [
        "#Redes neuronales - problema  balanceado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A__gbg8EC8S",
        "outputId": "3b5f87ac-87d0-4718-b739-37c8e675a0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "modelo = neural.MLPClassifier(solver='adam',activation='relu',hidden_layer_sizes=(900,450,200),alpha=0.1,max_iter=200,verbose=True,momentum=0.5)\n",
        "modelo.fit(X2,Y2)\n",
        "accuracy=modelo.score(X_val2,Y_val2)\n",
        "print(accuracy,modelo.score(X_test2,Y_test2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1.61208333\n",
            "Iteration 2, loss = 1.21042051\n",
            "Iteration 3, loss = 1.02789277\n",
            "Iteration 4, loss = 0.89275747\n",
            "Iteration 5, loss = 0.72097103\n",
            "Iteration 6, loss = 0.58817801\n",
            "Iteration 7, loss = 0.52597861\n",
            "Iteration 8, loss = 0.46970627\n",
            "Iteration 9, loss = 0.46521833\n",
            "Iteration 10, loss = 0.44173871\n",
            "Iteration 11, loss = 0.43324509\n",
            "Iteration 12, loss = 0.42202867\n",
            "Iteration 13, loss = 0.42100711\n",
            "Iteration 14, loss = 0.41258163\n",
            "Iteration 15, loss = 0.41124714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6789168278529981 0.5516041747197526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DODk4pT-1K5C"
      },
      "source": [
        "A partir de estos resultados se sabe que por la propagación de errores, el resultado de realizar un clasificador como el planteado va a ser insuficiente para el problema. Por esta razón, se descarta esta idea y se prueba solucionar este problema como un problema desbalanceado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTTZgdCyhBCY"
      },
      "source": [
        "#Redes neuronales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4BUzQTCvN2B"
      },
      "source": [
        "Se utilizan redes neuronales para resolver el problema, se piensa en primer lugar en una red con dos capas escondidas. Se varia el número de neuronas de cada una de estas y se encuentra el modelo con mejor accuracy. En total se entrenan 50 modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGMorTJuxXcM"
      },
      "source": [
        "#cantidad de neuronas\n",
        "capa2=[100,200,300,400,500] #Profundidad\n",
        "capa1=[100,200,300,400,500,600,700,800,900,1000] #cantidad de estimadores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMhq3qsHvTjM"
      },
      "source": [
        "#con 2 capas\n",
        "models= dict() #diccionario para guardar cada modelo\n",
        "accuracys= np.ones(50)#creacion array de unos para guardar el accuracy\n",
        "graficax= np.ones(50)#creacion array de unos para guardar el numero de stimadores\n",
        "graficay=np.ones(50)#creacion array de unos para guardar la progundidad\n",
        "modelo=np.ones(50)\n",
        "j=0\n",
        "for i in capa1:\n",
        "  for k in capa2:\n",
        "    models['model'+str(i)+'_'+str(k)]= Sequential()\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dense(i, input_dim=885, activation='relu'))\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dense(k, activation='relu'))\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dense(4, activation='softmax'))\n",
        "    adam =optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad= True) #Inicializar optimizador:Adam\n",
        "    models['model'+str(i)+'_'+str(k)].compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', 'mse']) # Compilar modelo\n",
        "    models['model'+str(i)+'_'+str(k)].fit(x=X, y=Y, epochs=15,class_weight=class_weights,validation_data=(X_val, Y_val))\n",
        "    datos = models['model'+str(i)+'_'+str(k)].evaluate(X_val, Y_val, verbose=0)\n",
        "    accuracys[j] =datos[1]*100\n",
        "    graficax[j]=i\n",
        "    graficay[j]=k\n",
        "    j=j+1\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqMVSeM-xqst"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUXK_gSmFJ47",
        "outputId": "aa16b8a1-a330-492a-9413-465b08e1a688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#encontrar el modelo con el mejor accuracy\n",
        "value2=np.max(accuracys)\n",
        "i2= np.where(accuracys == value2)\n",
        "\n",
        "maximo_x=graficax[i2[0][0]]\n",
        "\n",
        "maximo_y=graficay[i2[0][0]]\n",
        "print(\"Mejor modelo en los datos de validación ,usando \"+str(int(maximo_x))+\" neuronas en la primera capa y \"+str(int(maximo_y))+\" neuronas en la segunda capa, con un valor  de:\"+str(value2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor modelo en los datos de validación ,usando 400 neuronas en la primera capa y 100 neuronas en la segunda capa, con un valor  de:55.65801253357206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BX2qK6PwE1L"
      },
      "source": [
        "El mejor modelo fue aquel con 400 neuronas en la primera capa y 100 neuronas en la seguna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbiLMLoNBfe7"
      },
      "source": [
        "#Red neuronal Convolucional\n",
        "Se resuelve el problema de clasificación usando una red neuronal, en especifico se realiza una red convolucional. Entonces, las capas convolucionales que se usan son en una dimensión. Estas capas son utiles para que las redes neuronales aprendan caracteristicas secuencias de observaciones. Luego, pueden ser de utilidad en este caso al contar con diferentes secuencias de observaciones obtenidas mediante sensores.\n",
        "\n",
        "Cabe mencionar, que el comportamiento de la convolución en una dimensión es similar al de dos dimensiones. Luego, la diferencia radica en como cada uno los filtros  recorre la entrada y por supuesto la dimesionalidad de la entrada. En la convolución 1D cada una de las ventanas deslizantes(filtros) recorre la matriz de entrada de arriba hacia abajo, esto se realiza para cada uno de los datos de entrenamiento. Finalmete, cada uno de estos se suman y el resultado es pasado por la función de activación. Esto se repite para el número de filtros desaeados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLSTahl6V0vu"
      },
      "source": [
        "En primera instancia, se piensa en una red con dos capas covolucionales junto con una capa pooling como es tipico al usar capas convolucionales. Ademas, se agrega Dropout que permite que ciertas neuronas no se actualicen durante una época. Se varia el número de filtros con el fin de encontrar el más adecuado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFnTJlhOvVHA"
      },
      "source": [
        "#se ajustan los datos para ser correctamente utilizados en la convolución 1D\n",
        "X = X.reshape(89402, 885,1) #Reajuste de datos  entrenamiento\n",
        "X_val = X_val.reshape(11170, 885,1)#Reajuste de datos validación\n",
        "X_test = X_test.reshape(11180, 885,1)#Reajuste de datos test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRfSBWJGg4UD"
      },
      "source": [
        "capa2=[2,4,8,16,32] #Profundidad\n",
        "capa1=[2,4,8,16,32] #cantidad de estimadores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHgSFUr3gNtG",
        "outputId": "c95ffa88-61dd-419f-d60a-66466aa737cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#con 2 capas\n",
        "models= dict() #diccionario para guardar cada modelo\n",
        "accuracys= np.ones(25)#creacion array de unos para guardar el accuracy\n",
        "graficax= np.ones(25)#creacion array de unos para guardar el numero de stimadores\n",
        "graficay=np.ones(25)#creacion array de unos para guardar la progundidad\n",
        "modelo=dict()\n",
        "j=0\n",
        "for i in capa1:\n",
        "  for k in capa2:\n",
        "    models['model'+str(i)+'_'+str(k)] = Sequential() #Inicialización del modelo\n",
        "    models['model'+str(i)+'_'+str(k)].add(Conv1D(filters=i, kernel_size=3, activation='relu', input_shape=(885,1)))# Capa convolucional con 32 filtros y tamaño del kernel 3\n",
        "    models['model'+str(i)+'_'+str(k)].add(Conv1D(filters=k, kernel_size=3, activation='relu'))# Capa convolucional con 32 filtros y tamaño del kernel 3\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dropout(0.5)) #Dropout de 50%\n",
        "    models['model'+str(i)+'_'+str(k)].add(MaxPooling1D(pool_size=2)) # Capa poolig de tamaño 2\n",
        "    models['model'+str(i)+'_'+str(k)].add(Flatten()) # Capa Flatten\n",
        "    #parte totalmente conectada\n",
        "\n",
        "\n",
        "\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dense(4, activation='softmax'))\n",
        "    adam =optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, amsgrad= True) #Inicializar optimizador:Adam\n",
        "    models['model'+str(i)+'_'+str(k)].compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', 'mse']) # Compilar modelo\n",
        "    modelo['modelo'+str(i)+'_'+str(k)]=models['model'+str(i)+'_'+str(k)].fit(x=X, y=Y, epochs=25,class_weight=class_weights,validation_data=(X_val, Y_val))\n",
        "    datos = models['model'+str(i)+'_'+str(k)].evaluate(X_val, Y_val, verbose=0)\n",
        "    accuracys[j] =datos[1]*100\n",
        "    graficax[j]=i\n",
        "    graficay[j]=k\n",
        "    j=j+1\n",
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.7097 - acc: 0.3964 - mean_squared_error: 0.2015 - val_loss: 1.4960 - val_acc: 0.3953 - val_mean_squared_error: 0.1965\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 1.5062 - acc: 0.4353 - mean_squared_error: 0.1879 - val_loss: 1.3924 - val_acc: 0.4217 - val_mean_squared_error: 0.1879\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 1.3843 - acc: 0.4632 - mean_squared_error: 0.1787 - val_loss: 1.3204 - val_acc: 0.4478 - val_mean_squared_error: 0.1811\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 1.3046 - acc: 0.4867 - mean_squared_error: 0.1716 - val_loss: 1.2618 - val_acc: 0.4694 - val_mean_squared_error: 0.1750\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.2416 - acc: 0.5055 - mean_squared_error: 0.1657 - val_loss: 1.2233 - val_acc: 0.4841 - val_mean_squared_error: 0.1705\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.1974 - acc: 0.5205 - mean_squared_error: 0.1614 - val_loss: 1.1751 - val_acc: 0.4996 - val_mean_squared_error: 0.1650\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.1631 - acc: 0.5330 - mean_squared_error: 0.1578 - val_loss: 1.1545 - val_acc: 0.5098 - val_mean_squared_error: 0.1624\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.1350 - acc: 0.5422 - mean_squared_error: 0.1548 - val_loss: 1.1324 - val_acc: 0.5213 - val_mean_squared_error: 0.1598\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 1.1133 - acc: 0.5482 - mean_squared_error: 0.1526 - val_loss: 1.1153 - val_acc: 0.5295 - val_mean_squared_error: 0.1578\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.0947 - acc: 0.5548 - mean_squared_error: 0.1504 - val_loss: 1.0991 - val_acc: 0.5372 - val_mean_squared_error: 0.1557\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.0800 - acc: 0.5600 - mean_squared_error: 0.1488 - val_loss: 1.0955 - val_acc: 0.5385 - val_mean_squared_error: 0.1553\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.0642 - acc: 0.5655 - mean_squared_error: 0.1471 - val_loss: 1.0727 - val_acc: 0.5479 - val_mean_squared_error: 0.1524\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.0549 - acc: 0.5697 - mean_squared_error: 0.1458 - val_loss: 1.0687 - val_acc: 0.5490 - val_mean_squared_error: 0.1520\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 146us/step - loss: 1.0430 - acc: 0.5721 - mean_squared_error: 0.1447 - val_loss: 1.0627 - val_acc: 0.5525 - val_mean_squared_error: 0.1512\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.0366 - acc: 0.5746 - mean_squared_error: 0.1438 - val_loss: 1.0523 - val_acc: 0.5560 - val_mean_squared_error: 0.1498\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.0288 - acc: 0.5756 - mean_squared_error: 0.1430 - val_loss: 1.0403 - val_acc: 0.5603 - val_mean_squared_error: 0.1483\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.0200 - acc: 0.5785 - mean_squared_error: 0.1420 - val_loss: 1.0351 - val_acc: 0.5620 - val_mean_squared_error: 0.1476\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.0152 - acc: 0.5797 - mean_squared_error: 0.1413 - val_loss: 1.0229 - val_acc: 0.5659 - val_mean_squared_error: 0.1459\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.0078 - acc: 0.5829 - mean_squared_error: 0.1406 - val_loss: 1.0221 - val_acc: 0.5663 - val_mean_squared_error: 0.1459\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.0022 - acc: 0.5845 - mean_squared_error: 0.1398 - val_loss: 1.0118 - val_acc: 0.5727 - val_mean_squared_error: 0.1444\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9964 - acc: 0.5849 - mean_squared_error: 0.1391 - val_loss: 0.9993 - val_acc: 0.5783 - val_mean_squared_error: 0.1426\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9893 - acc: 0.5883 - mean_squared_error: 0.1382 - val_loss: 0.9959 - val_acc: 0.5792 - val_mean_squared_error: 0.1422\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9850 - acc: 0.5893 - mean_squared_error: 0.1377 - val_loss: 0.9897 - val_acc: 0.5828 - val_mean_squared_error: 0.1413\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.9791 - acc: 0.5915 - mean_squared_error: 0.1370 - val_loss: 0.9856 - val_acc: 0.5848 - val_mean_squared_error: 0.1407\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.9734 - acc: 0.5927 - mean_squared_error: 0.1362 - val_loss: 0.9745 - val_acc: 0.5898 - val_mean_squared_error: 0.1391\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 13s 148us/step - loss: 1.5902 - acc: 0.4344 - mean_squared_error: 0.1915 - val_loss: 1.4184 - val_acc: 0.4473 - val_mean_squared_error: 0.1869\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.3508 - acc: 0.4812 - mean_squared_error: 0.1745 - val_loss: 1.3329 - val_acc: 0.4719 - val_mean_squared_error: 0.1795\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 1.2443 - acc: 0.5100 - mean_squared_error: 0.1648 - val_loss: 1.2577 - val_acc: 0.4887 - val_mean_squared_error: 0.1730\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.1686 - acc: 0.5298 - mean_squared_error: 0.1577 - val_loss: 1.1869 - val_acc: 0.4995 - val_mean_squared_error: 0.1665\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.1178 - acc: 0.5470 - mean_squared_error: 0.1523 - val_loss: 1.1503 - val_acc: 0.5112 - val_mean_squared_error: 0.1627\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.0783 - acc: 0.5587 - mean_squared_error: 0.1481 - val_loss: 1.1136 - val_acc: 0.5230 - val_mean_squared_error: 0.1586\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.0434 - acc: 0.5697 - mean_squared_error: 0.1443 - val_loss: 1.0766 - val_acc: 0.5339 - val_mean_squared_error: 0.1543\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.0202 - acc: 0.5775 - mean_squared_error: 0.1418 - val_loss: 1.0472 - val_acc: 0.5446 - val_mean_squared_error: 0.1505\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9947 - acc: 0.5857 - mean_squared_error: 0.1389 - val_loss: 1.0244 - val_acc: 0.5531 - val_mean_squared_error: 0.1475\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9775 - acc: 0.5905 - mean_squared_error: 0.1368 - val_loss: 0.9994 - val_acc: 0.5668 - val_mean_squared_error: 0.1440\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9597 - acc: 0.5962 - mean_squared_error: 0.1346 - val_loss: 0.9762 - val_acc: 0.5786 - val_mean_squared_error: 0.1407\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9490 - acc: 0.6000 - mean_squared_error: 0.1334 - val_loss: 0.9671 - val_acc: 0.5838 - val_mean_squared_error: 0.1392\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9364 - acc: 0.6024 - mean_squared_error: 0.1319 - val_loss: 0.9549 - val_acc: 0.5904 - val_mean_squared_error: 0.1374\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 149us/step - loss: 0.9312 - acc: 0.6056 - mean_squared_error: 0.1312 - val_loss: 0.9404 - val_acc: 0.5991 - val_mean_squared_error: 0.1352\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9204 - acc: 0.6087 - mean_squared_error: 0.1298 - val_loss: 0.9337 - val_acc: 0.6025 - val_mean_squared_error: 0.1342\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9116 - acc: 0.6117 - mean_squared_error: 0.1287 - val_loss: 0.9277 - val_acc: 0.6044 - val_mean_squared_error: 0.1332\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9087 - acc: 0.6138 - mean_squared_error: 0.1282 - val_loss: 0.9191 - val_acc: 0.6102 - val_mean_squared_error: 0.1318\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9003 - acc: 0.6165 - mean_squared_error: 0.1271 - val_loss: 0.9115 - val_acc: 0.6142 - val_mean_squared_error: 0.1307\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8942 - acc: 0.6192 - mean_squared_error: 0.1264 - val_loss: 0.9011 - val_acc: 0.6179 - val_mean_squared_error: 0.1291\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8906 - acc: 0.6210 - mean_squared_error: 0.1258 - val_loss: 0.9007 - val_acc: 0.6195 - val_mean_squared_error: 0.1290\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.8847 - acc: 0.6232 - mean_squared_error: 0.1251 - val_loss: 0.8951 - val_acc: 0.6193 - val_mean_squared_error: 0.1281\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8827 - acc: 0.6245 - mean_squared_error: 0.1247 - val_loss: 0.9013 - val_acc: 0.6170 - val_mean_squared_error: 0.1290\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8787 - acc: 0.6287 - mean_squared_error: 0.1241 - val_loss: 0.8950 - val_acc: 0.6207 - val_mean_squared_error: 0.1280\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8755 - acc: 0.6282 - mean_squared_error: 0.1237 - val_loss: 0.8942 - val_acc: 0.6212 - val_mean_squared_error: 0.1279\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8727 - acc: 0.6297 - mean_squared_error: 0.1233 - val_loss: 0.8907 - val_acc: 0.6237 - val_mean_squared_error: 0.1274\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 13s 148us/step - loss: 1.3733 - acc: 0.4627 - mean_squared_error: 0.1779 - val_loss: 1.2527 - val_acc: 0.4838 - val_mean_squared_error: 0.1729\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 1.2057 - acc: 0.5172 - mean_squared_error: 0.1616 - val_loss: 1.1758 - val_acc: 0.5117 - val_mean_squared_error: 0.1645\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.1113 - acc: 0.5467 - mean_squared_error: 0.1517 - val_loss: 1.0600 - val_acc: 0.5434 - val_mean_squared_error: 0.1518\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.0401 - acc: 0.5716 - mean_squared_error: 0.1439 - val_loss: 0.9897 - val_acc: 0.5691 - val_mean_squared_error: 0.1425\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9926 - acc: 0.5847 - mean_squared_error: 0.1385 - val_loss: 0.9549 - val_acc: 0.5882 - val_mean_squared_error: 0.1377\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.9556 - acc: 0.5972 - mean_squared_error: 0.1341 - val_loss: 0.9106 - val_acc: 0.6090 - val_mean_squared_error: 0.1311\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.9311 - acc: 0.6071 - mean_squared_error: 0.1310 - val_loss: 0.8866 - val_acc: 0.6226 - val_mean_squared_error: 0.1272\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9165 - acc: 0.6106 - mean_squared_error: 0.1291 - val_loss: 0.8770 - val_acc: 0.6286 - val_mean_squared_error: 0.1257\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.9003 - acc: 0.6181 - mean_squared_error: 0.1273 - val_loss: 0.8670 - val_acc: 0.6336 - val_mean_squared_error: 0.1242\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8892 - acc: 0.6254 - mean_squared_error: 0.1256 - val_loss: 0.8640 - val_acc: 0.6373 - val_mean_squared_error: 0.1237\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8797 - acc: 0.6273 - mean_squared_error: 0.1244 - val_loss: 0.8589 - val_acc: 0.6415 - val_mean_squared_error: 0.1229\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8746 - acc: 0.6282 - mean_squared_error: 0.1237 - val_loss: 0.8589 - val_acc: 0.6417 - val_mean_squared_error: 0.1228\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8655 - acc: 0.6342 - mean_squared_error: 0.1225 - val_loss: 0.8528 - val_acc: 0.6459 - val_mean_squared_error: 0.1219\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8604 - acc: 0.6358 - mean_squared_error: 0.1218 - val_loss: 0.8524 - val_acc: 0.6475 - val_mean_squared_error: 0.1218\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.8551 - acc: 0.6391 - mean_squared_error: 0.1211 - val_loss: 0.8457 - val_acc: 0.6513 - val_mean_squared_error: 0.1209\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8507 - acc: 0.6399 - mean_squared_error: 0.1205 - val_loss: 0.8471 - val_acc: 0.6501 - val_mean_squared_error: 0.1210\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8483 - acc: 0.6406 - mean_squared_error: 0.1202 - val_loss: 0.8452 - val_acc: 0.6517 - val_mean_squared_error: 0.1207\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8435 - acc: 0.6449 - mean_squared_error: 0.1195 - val_loss: 0.8420 - val_acc: 0.6493 - val_mean_squared_error: 0.1202\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8405 - acc: 0.6456 - mean_squared_error: 0.1190 - val_loss: 0.8462 - val_acc: 0.6512 - val_mean_squared_error: 0.1208\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8375 - acc: 0.6465 - mean_squared_error: 0.1187 - val_loss: 0.8428 - val_acc: 0.6540 - val_mean_squared_error: 0.1203\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8352 - acc: 0.6494 - mean_squared_error: 0.1183 - val_loss: 0.8415 - val_acc: 0.6521 - val_mean_squared_error: 0.1201\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8312 - acc: 0.6500 - mean_squared_error: 0.1178 - val_loss: 0.8426 - val_acc: 0.6524 - val_mean_squared_error: 0.1202\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8298 - acc: 0.6510 - mean_squared_error: 0.1176 - val_loss: 0.8454 - val_acc: 0.6520 - val_mean_squared_error: 0.1205\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8281 - acc: 0.6526 - mean_squared_error: 0.1173 - val_loss: 0.8410 - val_acc: 0.6568 - val_mean_squared_error: 0.1199\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8257 - acc: 0.6527 - mean_squared_error: 0.1170 - val_loss: 0.8369 - val_acc: 0.6530 - val_mean_squared_error: 0.1193\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 152us/step - loss: 1.2314 - acc: 0.5105 - mean_squared_error: 0.1665 - val_loss: 1.1835 - val_acc: 0.4908 - val_mean_squared_error: 0.1671\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.0666 - acc: 0.5664 - mean_squared_error: 0.1475 - val_loss: 1.0781 - val_acc: 0.5319 - val_mean_squared_error: 0.1543\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.9939 - acc: 0.5825 - mean_squared_error: 0.1394 - val_loss: 1.0151 - val_acc: 0.5590 - val_mean_squared_error: 0.1463\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9559 - acc: 0.5933 - mean_squared_error: 0.1348 - val_loss: 0.9814 - val_acc: 0.5718 - val_mean_squared_error: 0.1418\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9345 - acc: 0.5991 - mean_squared_error: 0.1321 - val_loss: 0.9512 - val_acc: 0.5868 - val_mean_squared_error: 0.1374\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9192 - acc: 0.6051 - mean_squared_error: 0.1301 - val_loss: 0.9351 - val_acc: 0.5988 - val_mean_squared_error: 0.1349\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9116 - acc: 0.6088 - mean_squared_error: 0.1290 - val_loss: 0.9324 - val_acc: 0.5994 - val_mean_squared_error: 0.1347\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.9009 - acc: 0.6142 - mean_squared_error: 0.1276 - val_loss: 0.9210 - val_acc: 0.6065 - val_mean_squared_error: 0.1328\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8943 - acc: 0.6156 - mean_squared_error: 0.1267 - val_loss: 0.9197 - val_acc: 0.6065 - val_mean_squared_error: 0.1329\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8861 - acc: 0.6210 - mean_squared_error: 0.1257 - val_loss: 0.9208 - val_acc: 0.6095 - val_mean_squared_error: 0.1328\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8814 - acc: 0.6225 - mean_squared_error: 0.1250 - val_loss: 0.9157 - val_acc: 0.6117 - val_mean_squared_error: 0.1320\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8748 - acc: 0.6271 - mean_squared_error: 0.1240 - val_loss: 0.9010 - val_acc: 0.6185 - val_mean_squared_error: 0.1297\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 146us/step - loss: 0.8712 - acc: 0.6262 - mean_squared_error: 0.1236 - val_loss: 0.8997 - val_acc: 0.6190 - val_mean_squared_error: 0.1294\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8656 - acc: 0.6314 - mean_squared_error: 0.1228 - val_loss: 0.9009 - val_acc: 0.6215 - val_mean_squared_error: 0.1297\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8621 - acc: 0.6339 - mean_squared_error: 0.1223 - val_loss: 0.8959 - val_acc: 0.6238 - val_mean_squared_error: 0.1288\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8581 - acc: 0.6352 - mean_squared_error: 0.1218 - val_loss: 0.8931 - val_acc: 0.6249 - val_mean_squared_error: 0.1283\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8535 - acc: 0.6379 - mean_squared_error: 0.1212 - val_loss: 0.8857 - val_acc: 0.6317 - val_mean_squared_error: 0.1273\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8511 - acc: 0.6385 - mean_squared_error: 0.1208 - val_loss: 0.8907 - val_acc: 0.6286 - val_mean_squared_error: 0.1278\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8469 - acc: 0.6404 - mean_squared_error: 0.1202 - val_loss: 0.8921 - val_acc: 0.6271 - val_mean_squared_error: 0.1281\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8426 - acc: 0.6431 - mean_squared_error: 0.1197 - val_loss: 0.8835 - val_acc: 0.6298 - val_mean_squared_error: 0.1266\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8406 - acc: 0.6442 - mean_squared_error: 0.1194 - val_loss: 0.8769 - val_acc: 0.6345 - val_mean_squared_error: 0.1257\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8387 - acc: 0.6462 - mean_squared_error: 0.1191 - val_loss: 0.8819 - val_acc: 0.6324 - val_mean_squared_error: 0.1265\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8341 - acc: 0.6470 - mean_squared_error: 0.1185 - val_loss: 0.8813 - val_acc: 0.6321 - val_mean_squared_error: 0.1262\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8311 - acc: 0.6478 - mean_squared_error: 0.1181 - val_loss: 0.8725 - val_acc: 0.6376 - val_mean_squared_error: 0.1250\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8290 - acc: 0.6501 - mean_squared_error: 0.1177 - val_loss: 0.8747 - val_acc: 0.6356 - val_mean_squared_error: 0.1252\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 151us/step - loss: 1.1497 - acc: 0.5342 - mean_squared_error: 0.1570 - val_loss: 1.0673 - val_acc: 0.5469 - val_mean_squared_error: 0.1522\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 147us/step - loss: 0.9809 - acc: 0.5897 - mean_squared_error: 0.1373 - val_loss: 0.9495 - val_acc: 0.5980 - val_mean_squared_error: 0.1361\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.9036 - acc: 0.6168 - mean_squared_error: 0.1277 - val_loss: 0.8854 - val_acc: 0.6272 - val_mean_squared_error: 0.1272\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 13s 147us/step - loss: 0.8691 - acc: 0.6284 - mean_squared_error: 0.1232 - val_loss: 0.8620 - val_acc: 0.6496 - val_mean_squared_error: 0.1232\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8512 - acc: 0.6392 - mean_squared_error: 0.1206 - val_loss: 0.8434 - val_acc: 0.6583 - val_mean_squared_error: 0.1205\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8401 - acc: 0.6442 - mean_squared_error: 0.1191 - val_loss: 0.8288 - val_acc: 0.6641 - val_mean_squared_error: 0.1186\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8301 - acc: 0.6498 - mean_squared_error: 0.1177 - val_loss: 0.8323 - val_acc: 0.6585 - val_mean_squared_error: 0.1193\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 147us/step - loss: 0.8238 - acc: 0.6526 - mean_squared_error: 0.1168 - val_loss: 0.8289 - val_acc: 0.6629 - val_mean_squared_error: 0.1187\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8190 - acc: 0.6561 - mean_squared_error: 0.1161 - val_loss: 0.8310 - val_acc: 0.6631 - val_mean_squared_error: 0.1189\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8140 - acc: 0.6585 - mean_squared_error: 0.1156 - val_loss: 0.8190 - val_acc: 0.6697 - val_mean_squared_error: 0.1173\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 146us/step - loss: 0.8094 - acc: 0.6596 - mean_squared_error: 0.1148 - val_loss: 0.8265 - val_acc: 0.6667 - val_mean_squared_error: 0.1182\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 14s 152us/step - loss: 0.8034 - acc: 0.6636 - mean_squared_error: 0.1140 - val_loss: 0.8243 - val_acc: 0.6685 - val_mean_squared_error: 0.1179\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8012 - acc: 0.6641 - mean_squared_error: 0.1137 - val_loss: 0.8190 - val_acc: 0.6697 - val_mean_squared_error: 0.1173\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 148us/step - loss: 0.7971 - acc: 0.6661 - mean_squared_error: 0.1132 - val_loss: 0.8154 - val_acc: 0.6717 - val_mean_squared_error: 0.1167\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.7940 - acc: 0.6676 - mean_squared_error: 0.1128 - val_loss: 0.8164 - val_acc: 0.6705 - val_mean_squared_error: 0.1168\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.7898 - acc: 0.6697 - mean_squared_error: 0.1123 - val_loss: 0.8139 - val_acc: 0.6680 - val_mean_squared_error: 0.1167\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.7856 - acc: 0.6717 - mean_squared_error: 0.1117 - val_loss: 0.8107 - val_acc: 0.6722 - val_mean_squared_error: 0.1160\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.7840 - acc: 0.6713 - mean_squared_error: 0.1116 - val_loss: 0.8116 - val_acc: 0.6707 - val_mean_squared_error: 0.1161\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7803 - acc: 0.6743 - mean_squared_error: 0.1109 - val_loss: 0.8095 - val_acc: 0.6720 - val_mean_squared_error: 0.1159\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7775 - acc: 0.6747 - mean_squared_error: 0.1106 - val_loss: 0.8082 - val_acc: 0.6718 - val_mean_squared_error: 0.1156\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.7758 - acc: 0.6751 - mean_squared_error: 0.1103 - val_loss: 0.8046 - val_acc: 0.6755 - val_mean_squared_error: 0.1150\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.7730 - acc: 0.6766 - mean_squared_error: 0.1100 - val_loss: 0.8073 - val_acc: 0.6715 - val_mean_squared_error: 0.1153\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.7691 - acc: 0.6768 - mean_squared_error: 0.1095 - val_loss: 0.8076 - val_acc: 0.6736 - val_mean_squared_error: 0.1154\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.7659 - acc: 0.6793 - mean_squared_error: 0.1090 - val_loss: 0.7972 - val_acc: 0.6766 - val_mean_squared_error: 0.1139\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.7631 - acc: 0.6803 - mean_squared_error: 0.1086 - val_loss: 0.8046 - val_acc: 0.6749 - val_mean_squared_error: 0.1149\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 13s 147us/step - loss: 1.6922 - acc: 0.3784 - mean_squared_error: 0.2050 - val_loss: 1.4362 - val_acc: 0.4349 - val_mean_squared_error: 0.1897\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.4388 - acc: 0.4566 - mean_squared_error: 0.1822 - val_loss: 1.3378 - val_acc: 0.4555 - val_mean_squared_error: 0.1818\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.3307 - acc: 0.4869 - mean_squared_error: 0.1733 - val_loss: 1.2663 - val_acc: 0.4700 - val_mean_squared_error: 0.1749\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.2536 - acc: 0.5097 - mean_squared_error: 0.1666 - val_loss: 1.2128 - val_acc: 0.4865 - val_mean_squared_error: 0.1692\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 1.1927 - acc: 0.5249 - mean_squared_error: 0.1608 - val_loss: 1.1662 - val_acc: 0.4993 - val_mean_squared_error: 0.1641\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 1.1464 - acc: 0.5381 - mean_squared_error: 0.1564 - val_loss: 1.1247 - val_acc: 0.5117 - val_mean_squared_error: 0.1592\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.1177 - acc: 0.5447 - mean_squared_error: 0.1536 - val_loss: 1.0953 - val_acc: 0.5210 - val_mean_squared_error: 0.1557\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.0926 - acc: 0.5516 - mean_squared_error: 0.1511 - val_loss: 1.0756 - val_acc: 0.5302 - val_mean_squared_error: 0.1535\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 1.0702 - acc: 0.5573 - mean_squared_error: 0.1487 - val_loss: 1.0563 - val_acc: 0.5391 - val_mean_squared_error: 0.1512\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.0550 - acc: 0.5598 - mean_squared_error: 0.1472 - val_loss: 1.0440 - val_acc: 0.5441 - val_mean_squared_error: 0.1498\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 1.0433 - acc: 0.5638 - mean_squared_error: 0.1459 - val_loss: 1.0348 - val_acc: 0.5485 - val_mean_squared_error: 0.1488\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.0311 - acc: 0.5668 - mean_squared_error: 0.1444 - val_loss: 1.0271 - val_acc: 0.5522 - val_mean_squared_error: 0.1479\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.0217 - acc: 0.5688 - mean_squared_error: 0.1433 - val_loss: 1.0169 - val_acc: 0.5599 - val_mean_squared_error: 0.1466\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.0117 - acc: 0.5726 - mean_squared_error: 0.1420 - val_loss: 1.0134 - val_acc: 0.5611 - val_mean_squared_error: 0.1464\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.0035 - acc: 0.5742 - mean_squared_error: 0.1409 - val_loss: 1.0121 - val_acc: 0.5611 - val_mean_squared_error: 0.1465\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.9947 - acc: 0.5766 - mean_squared_error: 0.1399 - val_loss: 1.0008 - val_acc: 0.5658 - val_mean_squared_error: 0.1449\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9881 - acc: 0.5783 - mean_squared_error: 0.1390 - val_loss: 0.9956 - val_acc: 0.5685 - val_mean_squared_error: 0.1443\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.9782 - acc: 0.5831 - mean_squared_error: 0.1379 - val_loss: 0.9962 - val_acc: 0.5697 - val_mean_squared_error: 0.1446\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 0.9714 - acc: 0.5838 - mean_squared_error: 0.1371 - val_loss: 0.9887 - val_acc: 0.5718 - val_mean_squared_error: 0.1436\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.9647 - acc: 0.5867 - mean_squared_error: 0.1361 - val_loss: 0.9802 - val_acc: 0.5759 - val_mean_squared_error: 0.1424\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.9593 - acc: 0.5888 - mean_squared_error: 0.1355 - val_loss: 0.9765 - val_acc: 0.5777 - val_mean_squared_error: 0.1420\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9527 - acc: 0.5908 - mean_squared_error: 0.1346 - val_loss: 0.9726 - val_acc: 0.5796 - val_mean_squared_error: 0.1416\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9460 - acc: 0.5957 - mean_squared_error: 0.1337 - val_loss: 0.9695 - val_acc: 0.5807 - val_mean_squared_error: 0.1412\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.9411 - acc: 0.5956 - mean_squared_error: 0.1331 - val_loss: 0.9659 - val_acc: 0.5816 - val_mean_squared_error: 0.1407\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.9334 - acc: 0.5991 - mean_squared_error: 0.1320 - val_loss: 0.9635 - val_acc: 0.5838 - val_mean_squared_error: 0.1404\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 153us/step - loss: 1.4766 - acc: 0.4217 - mean_squared_error: 0.1880 - val_loss: 1.2977 - val_acc: 0.4629 - val_mean_squared_error: 0.1790\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.3142 - acc: 0.4849 - mean_squared_error: 0.1725 - val_loss: 1.2305 - val_acc: 0.4885 - val_mean_squared_error: 0.1717\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.2250 - acc: 0.5146 - mean_squared_error: 0.1637 - val_loss: 1.1906 - val_acc: 0.5048 - val_mean_squared_error: 0.1670\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 1.1646 - acc: 0.5339 - mean_squared_error: 0.1576 - val_loss: 1.1551 - val_acc: 0.5186 - val_mean_squared_error: 0.1628\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.1215 - acc: 0.5488 - mean_squared_error: 0.1531 - val_loss: 1.1209 - val_acc: 0.5304 - val_mean_squared_error: 0.1588\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.0889 - acc: 0.5586 - mean_squared_error: 0.1496 - val_loss: 1.0875 - val_acc: 0.5412 - val_mean_squared_error: 0.1550\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.0532 - acc: 0.5687 - mean_squared_error: 0.1457 - val_loss: 1.0541 - val_acc: 0.5527 - val_mean_squared_error: 0.1509\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 1.0268 - acc: 0.5762 - mean_squared_error: 0.1428 - val_loss: 1.0363 - val_acc: 0.5551 - val_mean_squared_error: 0.1488\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 1.0044 - acc: 0.5820 - mean_squared_error: 0.1404 - val_loss: 1.0053 - val_acc: 0.5696 - val_mean_squared_error: 0.1445\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9846 - acc: 0.5870 - mean_squared_error: 0.1381 - val_loss: 0.9865 - val_acc: 0.5758 - val_mean_squared_error: 0.1420\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.9709 - acc: 0.5923 - mean_squared_error: 0.1364 - val_loss: 0.9657 - val_acc: 0.5875 - val_mean_squared_error: 0.1389\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9553 - acc: 0.5945 - mean_squared_error: 0.1345 - val_loss: 0.9552 - val_acc: 0.5914 - val_mean_squared_error: 0.1376\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.9435 - acc: 0.5987 - mean_squared_error: 0.1330 - val_loss: 0.9457 - val_acc: 0.5960 - val_mean_squared_error: 0.1362\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9353 - acc: 0.6021 - mean_squared_error: 0.1318 - val_loss: 0.9322 - val_acc: 0.6047 - val_mean_squared_error: 0.1343\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.9263 - acc: 0.6055 - mean_squared_error: 0.1306 - val_loss: 0.9245 - val_acc: 0.6085 - val_mean_squared_error: 0.1333\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9166 - acc: 0.6083 - mean_squared_error: 0.1294 - val_loss: 0.9216 - val_acc: 0.6089 - val_mean_squared_error: 0.1331\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9101 - acc: 0.6116 - mean_squared_error: 0.1286 - val_loss: 0.9080 - val_acc: 0.6210 - val_mean_squared_error: 0.1309\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9033 - acc: 0.6148 - mean_squared_error: 0.1275 - val_loss: 0.9008 - val_acc: 0.6236 - val_mean_squared_error: 0.1299\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8992 - acc: 0.6146 - mean_squared_error: 0.1271 - val_loss: 0.8989 - val_acc: 0.6261 - val_mean_squared_error: 0.1296\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.8939 - acc: 0.6181 - mean_squared_error: 0.1263 - val_loss: 0.8895 - val_acc: 0.6307 - val_mean_squared_error: 0.1283\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8870 - acc: 0.6228 - mean_squared_error: 0.1254 - val_loss: 0.8858 - val_acc: 0.6336 - val_mean_squared_error: 0.1277\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8849 - acc: 0.6231 - mean_squared_error: 0.1250 - val_loss: 0.8805 - val_acc: 0.6356 - val_mean_squared_error: 0.1269\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8798 - acc: 0.6256 - mean_squared_error: 0.1243 - val_loss: 0.8728 - val_acc: 0.6399 - val_mean_squared_error: 0.1257\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8739 - acc: 0.6268 - mean_squared_error: 0.1236 - val_loss: 0.8724 - val_acc: 0.6425 - val_mean_squared_error: 0.1256\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.8720 - acc: 0.6299 - mean_squared_error: 0.1233 - val_loss: 0.8652 - val_acc: 0.6457 - val_mean_squared_error: 0.1245\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 152us/step - loss: 1.3233 - acc: 0.4674 - mean_squared_error: 0.1749 - val_loss: 1.2806 - val_acc: 0.4695 - val_mean_squared_error: 0.1775\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.1578 - acc: 0.5353 - mean_squared_error: 0.1572 - val_loss: 1.1593 - val_acc: 0.5087 - val_mean_squared_error: 0.1639\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 1.0694 - acc: 0.5627 - mean_squared_error: 0.1476 - val_loss: 1.0871 - val_acc: 0.5382 - val_mean_squared_error: 0.1552\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 1.0089 - acc: 0.5830 - mean_squared_error: 0.1405 - val_loss: 1.0303 - val_acc: 0.5552 - val_mean_squared_error: 0.1477\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9709 - acc: 0.5919 - mean_squared_error: 0.1362 - val_loss: 0.9831 - val_acc: 0.5766 - val_mean_squared_error: 0.1412\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9446 - acc: 0.6004 - mean_squared_error: 0.1330 - val_loss: 0.9435 - val_acc: 0.5978 - val_mean_squared_error: 0.1354\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9210 - acc: 0.6091 - mean_squared_error: 0.1299 - val_loss: 0.9299 - val_acc: 0.6056 - val_mean_squared_error: 0.1336\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9080 - acc: 0.6134 - mean_squared_error: 0.1283 - val_loss: 0.9135 - val_acc: 0.6149 - val_mean_squared_error: 0.1311\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8942 - acc: 0.6188 - mean_squared_error: 0.1264 - val_loss: 0.8981 - val_acc: 0.6229 - val_mean_squared_error: 0.1289\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8842 - acc: 0.6224 - mean_squared_error: 0.1251 - val_loss: 0.8769 - val_acc: 0.6378 - val_mean_squared_error: 0.1255\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 147us/step - loss: 0.8760 - acc: 0.6277 - mean_squared_error: 0.1238 - val_loss: 0.8738 - val_acc: 0.6384 - val_mean_squared_error: 0.1252\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8675 - acc: 0.6314 - mean_squared_error: 0.1229 - val_loss: 0.8651 - val_acc: 0.6442 - val_mean_squared_error: 0.1238\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8612 - acc: 0.6338 - mean_squared_error: 0.1219 - val_loss: 0.8592 - val_acc: 0.6497 - val_mean_squared_error: 0.1229\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8523 - acc: 0.6386 - mean_squared_error: 0.1207 - val_loss: 0.8568 - val_acc: 0.6482 - val_mean_squared_error: 0.1226\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8495 - acc: 0.6396 - mean_squared_error: 0.1204 - val_loss: 0.8476 - val_acc: 0.6557 - val_mean_squared_error: 0.1211\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8440 - acc: 0.6432 - mean_squared_error: 0.1194 - val_loss: 0.8456 - val_acc: 0.6593 - val_mean_squared_error: 0.1208\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8402 - acc: 0.6455 - mean_squared_error: 0.1189 - val_loss: 0.8391 - val_acc: 0.6630 - val_mean_squared_error: 0.1198\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8360 - acc: 0.6475 - mean_squared_error: 0.1183 - val_loss: 0.8357 - val_acc: 0.6650 - val_mean_squared_error: 0.1192\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 0.8309 - acc: 0.6494 - mean_squared_error: 0.1177 - val_loss: 0.8338 - val_acc: 0.6664 - val_mean_squared_error: 0.1189\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.8268 - acc: 0.6516 - mean_squared_error: 0.1171 - val_loss: 0.8295 - val_acc: 0.6682 - val_mean_squared_error: 0.1183\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8267 - acc: 0.6526 - mean_squared_error: 0.1170 - val_loss: 0.8313 - val_acc: 0.6688 - val_mean_squared_error: 0.1184\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 0.8229 - acc: 0.6554 - mean_squared_error: 0.1164 - val_loss: 0.8245 - val_acc: 0.6693 - val_mean_squared_error: 0.1175\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.8199 - acc: 0.6559 - mean_squared_error: 0.1161 - val_loss: 0.8214 - val_acc: 0.6722 - val_mean_squared_error: 0.1170\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8193 - acc: 0.6564 - mean_squared_error: 0.1159 - val_loss: 0.8232 - val_acc: 0.6703 - val_mean_squared_error: 0.1172\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.8157 - acc: 0.6583 - mean_squared_error: 0.1155 - val_loss: 0.8242 - val_acc: 0.6713 - val_mean_squared_error: 0.1174\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 151us/step - loss: 1.3185 - acc: 0.4753 - mean_squared_error: 0.1733 - val_loss: 1.1922 - val_acc: 0.4930 - val_mean_squared_error: 0.1671\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.1164 - acc: 0.5434 - mean_squared_error: 0.1519 - val_loss: 1.0519 - val_acc: 0.5398 - val_mean_squared_error: 0.1510\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 1.0263 - acc: 0.5775 - mean_squared_error: 0.1418 - val_loss: 0.9764 - val_acc: 0.5818 - val_mean_squared_error: 0.1407\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 12s 135us/step - loss: 0.9619 - acc: 0.5975 - mean_squared_error: 0.1344 - val_loss: 0.9038 - val_acc: 0.6175 - val_mean_squared_error: 0.1299\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.9172 - acc: 0.6127 - mean_squared_error: 0.1292 - val_loss: 0.8609 - val_acc: 0.6397 - val_mean_squared_error: 0.1233\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8891 - acc: 0.6264 - mean_squared_error: 0.1255 - val_loss: 0.8424 - val_acc: 0.6501 - val_mean_squared_error: 0.1204\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8720 - acc: 0.6319 - mean_squared_error: 0.1233 - val_loss: 0.8382 - val_acc: 0.6545 - val_mean_squared_error: 0.1197\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.8604 - acc: 0.6373 - mean_squared_error: 0.1217 - val_loss: 0.8295 - val_acc: 0.6628 - val_mean_squared_error: 0.1184\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 0.8520 - acc: 0.6428 - mean_squared_error: 0.1204 - val_loss: 0.8227 - val_acc: 0.6688 - val_mean_squared_error: 0.1172\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8407 - acc: 0.6473 - mean_squared_error: 0.1190 - val_loss: 0.8171 - val_acc: 0.6709 - val_mean_squared_error: 0.1165\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8334 - acc: 0.6493 - mean_squared_error: 0.1180 - val_loss: 0.8210 - val_acc: 0.6698 - val_mean_squared_error: 0.1170\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 0.8306 - acc: 0.6501 - mean_squared_error: 0.1177 - val_loss: 0.8124 - val_acc: 0.6747 - val_mean_squared_error: 0.1157\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 0.8242 - acc: 0.6533 - mean_squared_error: 0.1167 - val_loss: 0.8109 - val_acc: 0.6759 - val_mean_squared_error: 0.1155\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.8218 - acc: 0.6561 - mean_squared_error: 0.1165 - val_loss: 0.8097 - val_acc: 0.6753 - val_mean_squared_error: 0.1153\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8166 - acc: 0.6574 - mean_squared_error: 0.1157 - val_loss: 0.8090 - val_acc: 0.6775 - val_mean_squared_error: 0.1152\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8135 - acc: 0.6595 - mean_squared_error: 0.1152 - val_loss: 0.8043 - val_acc: 0.6804 - val_mean_squared_error: 0.1145\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8126 - acc: 0.6598 - mean_squared_error: 0.1152 - val_loss: 0.8073 - val_acc: 0.6773 - val_mean_squared_error: 0.1149\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8073 - acc: 0.6619 - mean_squared_error: 0.1144 - val_loss: 0.8050 - val_acc: 0.6780 - val_mean_squared_error: 0.1146\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8044 - acc: 0.6624 - mean_squared_error: 0.1140 - val_loss: 0.8012 - val_acc: 0.6816 - val_mean_squared_error: 0.1140\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8018 - acc: 0.6657 - mean_squared_error: 0.1136 - val_loss: 0.8044 - val_acc: 0.6789 - val_mean_squared_error: 0.1144\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8002 - acc: 0.6649 - mean_squared_error: 0.1134 - val_loss: 0.8005 - val_acc: 0.6807 - val_mean_squared_error: 0.1139\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.7973 - acc: 0.6687 - mean_squared_error: 0.1129 - val_loss: 0.8014 - val_acc: 0.6786 - val_mean_squared_error: 0.1140\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.7971 - acc: 0.6680 - mean_squared_error: 0.1129 - val_loss: 0.8008 - val_acc: 0.6806 - val_mean_squared_error: 0.1139\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 0.7934 - acc: 0.6698 - mean_squared_error: 0.1124 - val_loss: 0.7969 - val_acc: 0.6812 - val_mean_squared_error: 0.1134\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.7931 - acc: 0.6694 - mean_squared_error: 0.1124 - val_loss: 0.7960 - val_acc: 0.6829 - val_mean_squared_error: 0.1133\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 152us/step - loss: 1.1515 - acc: 0.5420 - mean_squared_error: 0.1573 - val_loss: 1.0934 - val_acc: 0.5359 - val_mean_squared_error: 0.1556\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.9906 - acc: 0.5875 - mean_squared_error: 0.1384 - val_loss: 0.9713 - val_acc: 0.5839 - val_mean_squared_error: 0.1394\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.9111 - acc: 0.6125 - mean_squared_error: 0.1287 - val_loss: 0.8921 - val_acc: 0.6256 - val_mean_squared_error: 0.1280\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8777 - acc: 0.6228 - mean_squared_error: 0.1245 - val_loss: 0.8663 - val_acc: 0.6374 - val_mean_squared_error: 0.1245\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8575 - acc: 0.6347 - mean_squared_error: 0.1217 - val_loss: 0.8609 - val_acc: 0.6472 - val_mean_squared_error: 0.1233\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8436 - acc: 0.6421 - mean_squared_error: 0.1198 - val_loss: 0.8252 - val_acc: 0.6626 - val_mean_squared_error: 0.1180\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8311 - acc: 0.6473 - mean_squared_error: 0.1181 - val_loss: 0.8260 - val_acc: 0.6640 - val_mean_squared_error: 0.1182\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8221 - acc: 0.6520 - mean_squared_error: 0.1168 - val_loss: 0.8254 - val_acc: 0.6659 - val_mean_squared_error: 0.1182\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8128 - acc: 0.6566 - mean_squared_error: 0.1155 - val_loss: 0.8054 - val_acc: 0.6739 - val_mean_squared_error: 0.1151\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 14s 152us/step - loss: 0.8058 - acc: 0.6607 - mean_squared_error: 0.1146 - val_loss: 0.8113 - val_acc: 0.6667 - val_mean_squared_error: 0.1162\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7983 - acc: 0.6630 - mean_squared_error: 0.1135 - val_loss: 0.8011 - val_acc: 0.6728 - val_mean_squared_error: 0.1146\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.7927 - acc: 0.6672 - mean_squared_error: 0.1126 - val_loss: 0.7990 - val_acc: 0.6739 - val_mean_squared_error: 0.1142\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7872 - acc: 0.6708 - mean_squared_error: 0.1120 - val_loss: 0.7959 - val_acc: 0.6751 - val_mean_squared_error: 0.1136\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.7844 - acc: 0.6714 - mean_squared_error: 0.1115 - val_loss: 0.8007 - val_acc: 0.6752 - val_mean_squared_error: 0.1144\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7772 - acc: 0.6736 - mean_squared_error: 0.1106 - val_loss: 0.7866 - val_acc: 0.6779 - val_mean_squared_error: 0.1125\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7730 - acc: 0.6760 - mean_squared_error: 0.1100 - val_loss: 0.7872 - val_acc: 0.6767 - val_mean_squared_error: 0.1123\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7694 - acc: 0.6771 - mean_squared_error: 0.1095 - val_loss: 0.7850 - val_acc: 0.6795 - val_mean_squared_error: 0.1120\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7664 - acc: 0.6792 - mean_squared_error: 0.1092 - val_loss: 0.7903 - val_acc: 0.6773 - val_mean_squared_error: 0.1126\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.7613 - acc: 0.6809 - mean_squared_error: 0.1084 - val_loss: 0.7864 - val_acc: 0.6774 - val_mean_squared_error: 0.1120\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7593 - acc: 0.6819 - mean_squared_error: 0.1082 - val_loss: 0.7819 - val_acc: 0.6819 - val_mean_squared_error: 0.1114\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.7546 - acc: 0.6850 - mean_squared_error: 0.1075 - val_loss: 0.7784 - val_acc: 0.6842 - val_mean_squared_error: 0.1110\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.7514 - acc: 0.6861 - mean_squared_error: 0.1071 - val_loss: 0.7756 - val_acc: 0.6813 - val_mean_squared_error: 0.1107\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.7490 - acc: 0.6871 - mean_squared_error: 0.1068 - val_loss: 0.7790 - val_acc: 0.6809 - val_mean_squared_error: 0.1110\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.7447 - acc: 0.6895 - mean_squared_error: 0.1062 - val_loss: 0.7754 - val_acc: 0.6803 - val_mean_squared_error: 0.1106\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.7414 - acc: 0.6898 - mean_squared_error: 0.1057 - val_loss: 0.7722 - val_acc: 0.6840 - val_mean_squared_error: 0.1101\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 154us/step - loss: 1.8185 - acc: 0.3848 - mean_squared_error: 0.2089 - val_loss: 1.4163 - val_acc: 0.4374 - val_mean_squared_error: 0.1878\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.4901 - acc: 0.4456 - mean_squared_error: 0.1860 - val_loss: 1.2651 - val_acc: 0.4659 - val_mean_squared_error: 0.1748\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 12s 137us/step - loss: 1.3238 - acc: 0.4870 - mean_squared_error: 0.1729 - val_loss: 1.1935 - val_acc: 0.4887 - val_mean_squared_error: 0.1669\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.2195 - acc: 0.5185 - mean_squared_error: 0.1630 - val_loss: 1.1353 - val_acc: 0.5114 - val_mean_squared_error: 0.1597\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 1.1550 - acc: 0.5359 - mean_squared_error: 0.1568 - val_loss: 1.0911 - val_acc: 0.5303 - val_mean_squared_error: 0.1539\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.1033 - acc: 0.5534 - mean_squared_error: 0.1513 - val_loss: 1.0642 - val_acc: 0.5462 - val_mean_squared_error: 0.1502\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 1.0676 - acc: 0.5627 - mean_squared_error: 0.1476 - val_loss: 1.0317 - val_acc: 0.5675 - val_mean_squared_error: 0.1454\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.0413 - acc: 0.5706 - mean_squared_error: 0.1446 - val_loss: 1.0164 - val_acc: 0.5788 - val_mean_squared_error: 0.1433\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 146us/step - loss: 1.0196 - acc: 0.5775 - mean_squared_error: 0.1422 - val_loss: 0.9994 - val_acc: 0.5864 - val_mean_squared_error: 0.1409\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.9977 - acc: 0.5845 - mean_squared_error: 0.1395 - val_loss: 0.9883 - val_acc: 0.5928 - val_mean_squared_error: 0.1396\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.9836 - acc: 0.5889 - mean_squared_error: 0.1378 - val_loss: 0.9806 - val_acc: 0.5938 - val_mean_squared_error: 0.1387\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.9705 - acc: 0.5937 - mean_squared_error: 0.1362 - val_loss: 0.9735 - val_acc: 0.5944 - val_mean_squared_error: 0.1379\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9608 - acc: 0.5968 - mean_squared_error: 0.1349 - val_loss: 0.9648 - val_acc: 0.5966 - val_mean_squared_error: 0.1367\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9523 - acc: 0.5981 - mean_squared_error: 0.1339 - val_loss: 0.9587 - val_acc: 0.5981 - val_mean_squared_error: 0.1359\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9435 - acc: 0.6004 - mean_squared_error: 0.1328 - val_loss: 0.9517 - val_acc: 0.6012 - val_mean_squared_error: 0.1350\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9339 - acc: 0.6047 - mean_squared_error: 0.1314 - val_loss: 0.9463 - val_acc: 0.6029 - val_mean_squared_error: 0.1343\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9286 - acc: 0.6070 - mean_squared_error: 0.1307 - val_loss: 0.9426 - val_acc: 0.6042 - val_mean_squared_error: 0.1338\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9227 - acc: 0.6089 - mean_squared_error: 0.1300 - val_loss: 0.9309 - val_acc: 0.6109 - val_mean_squared_error: 0.1321\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.9194 - acc: 0.6105 - mean_squared_error: 0.1293 - val_loss: 0.9263 - val_acc: 0.6124 - val_mean_squared_error: 0.1314\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.9135 - acc: 0.6108 - mean_squared_error: 0.1288 - val_loss: 0.9212 - val_acc: 0.6145 - val_mean_squared_error: 0.1307\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9090 - acc: 0.6133 - mean_squared_error: 0.1282 - val_loss: 0.9174 - val_acc: 0.6170 - val_mean_squared_error: 0.1302\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9058 - acc: 0.6160 - mean_squared_error: 0.1276 - val_loss: 0.9166 - val_acc: 0.6161 - val_mean_squared_error: 0.1301\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9006 - acc: 0.6171 - mean_squared_error: 0.1269 - val_loss: 0.9152 - val_acc: 0.6178 - val_mean_squared_error: 0.1299\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8983 - acc: 0.6184 - mean_squared_error: 0.1266 - val_loss: 0.9077 - val_acc: 0.6218 - val_mean_squared_error: 0.1288\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8931 - acc: 0.6199 - mean_squared_error: 0.1259 - val_loss: 0.9003 - val_acc: 0.6247 - val_mean_squared_error: 0.1276\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 157us/step - loss: 1.5208 - acc: 0.4259 - mean_squared_error: 0.1902 - val_loss: 1.3835 - val_acc: 0.4355 - val_mean_squared_error: 0.1886\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.3295 - acc: 0.4748 - mean_squared_error: 0.1750 - val_loss: 1.2787 - val_acc: 0.4673 - val_mean_squared_error: 0.1780\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.2157 - acc: 0.5126 - mean_squared_error: 0.1636 - val_loss: 1.1965 - val_acc: 0.4954 - val_mean_squared_error: 0.1684\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.1369 - acc: 0.5397 - mean_squared_error: 0.1554 - val_loss: 1.1404 - val_acc: 0.5141 - val_mean_squared_error: 0.1613\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.0894 - acc: 0.5534 - mean_squared_error: 0.1505 - val_loss: 1.0819 - val_acc: 0.5355 - val_mean_squared_error: 0.1542\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.0484 - acc: 0.5658 - mean_squared_error: 0.1461 - val_loss: 1.0443 - val_acc: 0.5509 - val_mean_squared_error: 0.1493\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 1.0199 - acc: 0.5730 - mean_squared_error: 0.1428 - val_loss: 1.0166 - val_acc: 0.5603 - val_mean_squared_error: 0.1458\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9987 - acc: 0.5802 - mean_squared_error: 0.1404 - val_loss: 0.9854 - val_acc: 0.5760 - val_mean_squared_error: 0.1416\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 13s 146us/step - loss: 0.9771 - acc: 0.5858 - mean_squared_error: 0.1378 - val_loss: 0.9652 - val_acc: 0.5872 - val_mean_squared_error: 0.1387\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.9658 - acc: 0.5901 - mean_squared_error: 0.1364 - val_loss: 0.9494 - val_acc: 0.5960 - val_mean_squared_error: 0.1364\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9506 - acc: 0.5958 - mean_squared_error: 0.1343 - val_loss: 0.9343 - val_acc: 0.6013 - val_mean_squared_error: 0.1344\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.9383 - acc: 0.5992 - mean_squared_error: 0.1326 - val_loss: 0.9227 - val_acc: 0.6073 - val_mean_squared_error: 0.1326\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.9278 - acc: 0.6033 - mean_squared_error: 0.1313 - val_loss: 0.9116 - val_acc: 0.6125 - val_mean_squared_error: 0.1312\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.9196 - acc: 0.6056 - mean_squared_error: 0.1301 - val_loss: 0.9017 - val_acc: 0.6187 - val_mean_squared_error: 0.1297\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9124 - acc: 0.6083 - mean_squared_error: 0.1292 - val_loss: 0.8907 - val_acc: 0.6257 - val_mean_squared_error: 0.1280\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.9047 - acc: 0.6138 - mean_squared_error: 0.1279 - val_loss: 0.8834 - val_acc: 0.6300 - val_mean_squared_error: 0.1269\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 146us/step - loss: 0.8985 - acc: 0.6170 - mean_squared_error: 0.1271 - val_loss: 0.8749 - val_acc: 0.6357 - val_mean_squared_error: 0.1256\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8907 - acc: 0.6198 - mean_squared_error: 0.1260 - val_loss: 0.8704 - val_acc: 0.6381 - val_mean_squared_error: 0.1249\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8858 - acc: 0.6208 - mean_squared_error: 0.1254 - val_loss: 0.8649 - val_acc: 0.6407 - val_mean_squared_error: 0.1242\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8804 - acc: 0.6259 - mean_squared_error: 0.1246 - val_loss: 0.8638 - val_acc: 0.6419 - val_mean_squared_error: 0.1241\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8761 - acc: 0.6280 - mean_squared_error: 0.1241 - val_loss: 0.8557 - val_acc: 0.6474 - val_mean_squared_error: 0.1228\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8721 - acc: 0.6297 - mean_squared_error: 0.1234 - val_loss: 0.8486 - val_acc: 0.6532 - val_mean_squared_error: 0.1216\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8668 - acc: 0.6311 - mean_squared_error: 0.1227 - val_loss: 0.8487 - val_acc: 0.6537 - val_mean_squared_error: 0.1217\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8620 - acc: 0.6350 - mean_squared_error: 0.1221 - val_loss: 0.8443 - val_acc: 0.6580 - val_mean_squared_error: 0.1210\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8597 - acc: 0.6365 - mean_squared_error: 0.1216 - val_loss: 0.8425 - val_acc: 0.6588 - val_mean_squared_error: 0.1207\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 159us/step - loss: 1.2803 - acc: 0.4925 - mean_squared_error: 0.1715 - val_loss: 1.2376 - val_acc: 0.4821 - val_mean_squared_error: 0.1731\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 1.1225 - acc: 0.5471 - mean_squared_error: 0.1540 - val_loss: 1.1234 - val_acc: 0.5259 - val_mean_squared_error: 0.1592\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 1.0364 - acc: 0.5709 - mean_squared_error: 0.1446 - val_loss: 1.0586 - val_acc: 0.5474 - val_mean_squared_error: 0.1518\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9882 - acc: 0.5846 - mean_squared_error: 0.1392 - val_loss: 1.0022 - val_acc: 0.5717 - val_mean_squared_error: 0.1444\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9528 - acc: 0.5943 - mean_squared_error: 0.1348 - val_loss: 0.9573 - val_acc: 0.5932 - val_mean_squared_error: 0.1377\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.9283 - acc: 0.6021 - mean_squared_error: 0.1316 - val_loss: 0.9309 - val_acc: 0.6057 - val_mean_squared_error: 0.1338\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.9087 - acc: 0.6096 - mean_squared_error: 0.1288 - val_loss: 0.9116 - val_acc: 0.6170 - val_mean_squared_error: 0.1308\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.8947 - acc: 0.6156 - mean_squared_error: 0.1269 - val_loss: 0.8928 - val_acc: 0.6293 - val_mean_squared_error: 0.1279\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8825 - acc: 0.6214 - mean_squared_error: 0.1252 - val_loss: 0.8792 - val_acc: 0.6368 - val_mean_squared_error: 0.1259\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8717 - acc: 0.6276 - mean_squared_error: 0.1236 - val_loss: 0.8631 - val_acc: 0.6477 - val_mean_squared_error: 0.1233\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8628 - acc: 0.6303 - mean_squared_error: 0.1224 - val_loss: 0.8569 - val_acc: 0.6526 - val_mean_squared_error: 0.1224\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 12s 136us/step - loss: 0.8560 - acc: 0.6359 - mean_squared_error: 0.1213 - val_loss: 0.8462 - val_acc: 0.6585 - val_mean_squared_error: 0.1208\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 12s 140us/step - loss: 0.8483 - acc: 0.6398 - mean_squared_error: 0.1202 - val_loss: 0.8455 - val_acc: 0.6594 - val_mean_squared_error: 0.1205\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8419 - acc: 0.6436 - mean_squared_error: 0.1192 - val_loss: 0.8389 - val_acc: 0.6645 - val_mean_squared_error: 0.1195\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8371 - acc: 0.6464 - mean_squared_error: 0.1185 - val_loss: 0.8291 - val_acc: 0.6672 - val_mean_squared_error: 0.1181\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8303 - acc: 0.6494 - mean_squared_error: 0.1176 - val_loss: 0.8250 - val_acc: 0.6685 - val_mean_squared_error: 0.1174\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8268 - acc: 0.6524 - mean_squared_error: 0.1171 - val_loss: 0.8260 - val_acc: 0.6693 - val_mean_squared_error: 0.1176\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8234 - acc: 0.6537 - mean_squared_error: 0.1166 - val_loss: 0.8244 - val_acc: 0.6708 - val_mean_squared_error: 0.1172\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8195 - acc: 0.6553 - mean_squared_error: 0.1160 - val_loss: 0.8162 - val_acc: 0.6739 - val_mean_squared_error: 0.1161\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8173 - acc: 0.6567 - mean_squared_error: 0.1158 - val_loss: 0.8173 - val_acc: 0.6740 - val_mean_squared_error: 0.1161\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8145 - acc: 0.6600 - mean_squared_error: 0.1152 - val_loss: 0.8146 - val_acc: 0.6748 - val_mean_squared_error: 0.1158\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8118 - acc: 0.6579 - mean_squared_error: 0.1149 - val_loss: 0.8169 - val_acc: 0.6729 - val_mean_squared_error: 0.1160\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8102 - acc: 0.6608 - mean_squared_error: 0.1147 - val_loss: 0.8147 - val_acc: 0.6754 - val_mean_squared_error: 0.1157\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8079 - acc: 0.6613 - mean_squared_error: 0.1144 - val_loss: 0.8134 - val_acc: 0.6784 - val_mean_squared_error: 0.1155\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8072 - acc: 0.6615 - mean_squared_error: 0.1143 - val_loss: 0.8094 - val_acc: 0.6793 - val_mean_squared_error: 0.1149\n",
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/25\n",
            "89402/89402 [==============================] - 14s 162us/step - loss: 1.2585 - acc: 0.4938 - mean_squared_error: 0.1679 - val_loss: 1.2065 - val_acc: 0.4931 - val_mean_squared_error: 0.1693\n",
            "Epoch 2/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 1.0816 - acc: 0.5535 - mean_squared_error: 0.1489 - val_loss: 1.0939 - val_acc: 0.5396 - val_mean_squared_error: 0.1557\n",
            "Epoch 3/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.9870 - acc: 0.5875 - mean_squared_error: 0.1381 - val_loss: 0.9769 - val_acc: 0.5815 - val_mean_squared_error: 0.1406\n",
            "Epoch 4/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.9320 - acc: 0.6051 - mean_squared_error: 0.1316 - val_loss: 0.9069 - val_acc: 0.6152 - val_mean_squared_error: 0.1306\n",
            "Epoch 5/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.8958 - acc: 0.6193 - mean_squared_error: 0.1267 - val_loss: 0.8757 - val_acc: 0.6302 - val_mean_squared_error: 0.1260\n",
            "Epoch 6/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8791 - acc: 0.6266 - mean_squared_error: 0.1245 - val_loss: 0.8608 - val_acc: 0.6386 - val_mean_squared_error: 0.1237\n",
            "Epoch 7/25\n",
            "89402/89402 [==============================] - 13s 147us/step - loss: 0.8658 - acc: 0.6318 - mean_squared_error: 0.1226 - val_loss: 0.8443 - val_acc: 0.6509 - val_mean_squared_error: 0.1212\n",
            "Epoch 8/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.8528 - acc: 0.6393 - mean_squared_error: 0.1209 - val_loss: 0.8393 - val_acc: 0.6554 - val_mean_squared_error: 0.1204\n",
            "Epoch 9/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8449 - acc: 0.6438 - mean_squared_error: 0.1198 - val_loss: 0.8266 - val_acc: 0.6584 - val_mean_squared_error: 0.1185\n",
            "Epoch 10/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8369 - acc: 0.6457 - mean_squared_error: 0.1188 - val_loss: 0.8204 - val_acc: 0.6651 - val_mean_squared_error: 0.1175\n",
            "Epoch 11/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8272 - acc: 0.6505 - mean_squared_error: 0.1174 - val_loss: 0.8248 - val_acc: 0.6663 - val_mean_squared_error: 0.1179\n",
            "Epoch 12/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8216 - acc: 0.6543 - mean_squared_error: 0.1165 - val_loss: 0.8187 - val_acc: 0.6680 - val_mean_squared_error: 0.1172\n",
            "Epoch 13/25\n",
            "89402/89402 [==============================] - 13s 141us/step - loss: 0.8164 - acc: 0.6568 - mean_squared_error: 0.1158 - val_loss: 0.8094 - val_acc: 0.6722 - val_mean_squared_error: 0.1158\n",
            "Epoch 14/25\n",
            "89402/89402 [==============================] - 12s 138us/step - loss: 0.8124 - acc: 0.6591 - mean_squared_error: 0.1152 - val_loss: 0.8072 - val_acc: 0.6735 - val_mean_squared_error: 0.1156\n",
            "Epoch 15/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.8084 - acc: 0.6603 - mean_squared_error: 0.1147 - val_loss: 0.8075 - val_acc: 0.6731 - val_mean_squared_error: 0.1155\n",
            "Epoch 16/25\n",
            "89402/89402 [==============================] - 12s 139us/step - loss: 0.8048 - acc: 0.6616 - mean_squared_error: 0.1143 - val_loss: 0.8101 - val_acc: 0.6737 - val_mean_squared_error: 0.1158\n",
            "Epoch 17/25\n",
            "89402/89402 [==============================] - 13s 140us/step - loss: 0.8004 - acc: 0.6654 - mean_squared_error: 0.1136 - val_loss: 0.8033 - val_acc: 0.6763 - val_mean_squared_error: 0.1148\n",
            "Epoch 18/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.7977 - acc: 0.6664 - mean_squared_error: 0.1133 - val_loss: 0.8095 - val_acc: 0.6763 - val_mean_squared_error: 0.1157\n",
            "Epoch 19/25\n",
            "89402/89402 [==============================] - 13s 142us/step - loss: 0.7946 - acc: 0.6674 - mean_squared_error: 0.1129 - val_loss: 0.8007 - val_acc: 0.6816 - val_mean_squared_error: 0.1142\n",
            "Epoch 20/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.7920 - acc: 0.6693 - mean_squared_error: 0.1124 - val_loss: 0.7965 - val_acc: 0.6805 - val_mean_squared_error: 0.1137\n",
            "Epoch 21/25\n",
            "89402/89402 [==============================] - 13s 143us/step - loss: 0.7904 - acc: 0.6687 - mean_squared_error: 0.1123 - val_loss: 0.7972 - val_acc: 0.6797 - val_mean_squared_error: 0.1139\n",
            "Epoch 22/25\n",
            "89402/89402 [==============================] - 13s 147us/step - loss: 0.7872 - acc: 0.6713 - mean_squared_error: 0.1118 - val_loss: 0.7957 - val_acc: 0.6825 - val_mean_squared_error: 0.1135\n",
            "Epoch 23/25\n",
            "89402/89402 [==============================] - 13s 145us/step - loss: 0.7843 - acc: 0.6715 - mean_squared_error: 0.1115 - val_loss: 0.7937 - val_acc: 0.6819 - val_mean_squared_error: 0.1134\n",
            "Epoch 24/25\n",
            "89402/89402 [==============================] - 13s 148us/step - loss: 0.7818 - acc: 0.6723 - mean_squared_error: 0.1111 - val_loss: 0.7970 - val_acc: 0.6789 - val_mean_squared_error: 0.1139\n",
            "Epoch 25/25\n",
            "89402/89402 [==============================] - 13s 144us/step - loss: 0.7786 - acc: 0.6749 - mean_squared_error: 0.1106 - val_loss: 0.7966 - val_acc: 0.6807 - val_mean_squared_error: 0.1137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-00d7db00f41c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodelo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'modelo'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdatos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0maccuracys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdatos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mgraficax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mgraficay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 26 is out of bounds for axis 0 with size 25"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaU04kGMOqRc",
        "outputId": "e2741fcf-7f22-4e59-b6ab-7b3e0f11ed8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#encontrar el modelo con el mejor accuracy\n",
        "value2=np.max(accuracys)\n",
        "i2= np.where(accuracys == value2)\n",
        "\n",
        "maximo_x=graficax[i2[0][0]]\n",
        "\n",
        "maximo_y=graficay[i2[0][0]]\n",
        "print(\"Mejor modelo en los datos de validación ,usando \"+str(int(maximo_x))+\" filtros en la primera capa y \"+str(int(maximo_y))+\" filtros en la segunda capa, con un valor  de:\"+str(value2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor modelo en los datos de validación ,usando 4 filtros en la primera capa y 32 filtros en la segunda capa, con un valor  de:68.39749328558639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kXlf144hLmX"
      },
      "source": [
        "Se evidencia una mejora significativa con recpecto a todos los otros metodos desarrollados, por esta razón se decide mejorar este tipo de red para alcanzar el maximo accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBiswTYdfVNS"
      },
      "source": [
        "Luego, se agregan dos capas totalmente conectadas. Dado la experiencia y la literatura tratada en el curso de machine se piensa que esto puede mejorar el comportamiento de la red. Se encuentra el número de nueronas adecuado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVLzW3paWW0i"
      },
      "source": [
        "capa2=[100,200,300,400,500] #Profundidad\n",
        "capa1=[100,200,300,400,500,600,700,800,900,1000] #cantidad de estimadores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxxAA-cnV6r_"
      },
      "source": [
        "#con 2 capas\n",
        "models= dict() #diccionario para guardar cada modelo\n",
        "accuracys= np.ones(50)#creacion array de unos para guardar el accuracy\n",
        "graficax= np.ones(50)#creacion array de unos para guardar el numero de stimadores\n",
        "graficay=np.ones(50)#creacion array de unos para guardar la progundidad\n",
        "modelo=dict()\n",
        "j=0\n",
        "for i in capa1:\n",
        "  for k in capa2:\n",
        "    models['model'+str(i)+'_'+str(k)] = Sequential() #Inicialización del modelo\n",
        "    models['model'+str(i)+'_'+str(k)].add(Conv1D(filters=4, kernel_size=3, activation='relu', input_shape=(885,1)))# Capa convolucional con 32 filtros y tamaño del kernel 3\n",
        "    models['model'+str(i)+'_'+str(k)].add(Conv1D(filters=32, kernel_size=3, activation='relu'))# Capa convolucional con 32 filtros y tamaño del kernel 3\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dropout(0.5)) #Dropout de 50%\n",
        "    models['model'+str(i)+'_'+str(k)].add(MaxPooling1D(pool_size=2)) # Capa poolig de tamaño 2\n",
        "    models['model'+str(i)+'_'+str(k)].add(Flatten()) # Capa Flatten\n",
        "    #parte totalmente conectada\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dense(i, activation='relu')) # Capa con 1000 neuronas\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dense(k, activation='relu'))  #\n",
        "\n",
        "\n",
        "    models['model'+str(i)+'_'+str(k)].add(Dense(4, activation='softmax'))\n",
        "    adam =optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, amsgrad= True) #Inicializar optimizador:Adam\n",
        "    models['model'+str(i)+'_'+str(k)].compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', 'mse']) # Compilar modelo\n",
        "    modelo['modelo'+str(i)+'_'+str(k)]=models['model'+str(i)+'_'+str(k)].fit(x=X, y=Y, epochs=15,class_weight=class_weights,validation_data=(X_val, Y_val))\n",
        "    datos = models['model'+str(i)+'_'+str(k)].evaluate(X_val, Y_val, verbose=0)\n",
        "    accuracys[j] =datos[1]*100\n",
        "    graficax[j]=i\n",
        "    graficay[j]=k\n",
        "    j=j+1\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "13784e59-9bbf-4f30-ecb8-523d3eb4f1ed",
        "id": "ca-Ynsj6WSyq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#encontrar el modelo con el mejor accuracy\n",
        "value2=np.max(accuracys)\n",
        "i2= np.where(accuracys == value2)\n",
        "\n",
        "maximo_x=graficax[i2[0][0]]\n",
        "\n",
        "maximo_y=graficay[i2[0][0]]\n",
        "print(\"Mejor modelo en los datos de validación ,usando \"+str(int(maximo_x))+\" neuronas en la primera capa y \"+str(int(maximo_y))+\" neuronas en la segunda capa, con un valor  de:\"+str(value2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor modelo en los datos de validación ,usando 1000 neuronas en la primera capa y 500 neuronas en la segunda capa, con un valor  de:69.21217547000896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juBtC6qtWfIj"
      },
      "source": [
        "Se oberva que el accuracy en los datos de validación mejoro, por lo tanto se dejan esta dos capas totalmente conectadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPTP4JJhfo6p"
      },
      "source": [
        "Después, se agrega regularización l1 a la parte totalmente conectada de la red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYF74hGDWelM"
      },
      "source": [
        "#con 2 capas\n",
        "models= dict() #diccionario para guardar cada modelo\n",
        "accuracys= np.ones(9)#creacion array de unos para guardar el accuracy\n",
        "graficax= np.ones(9)#creacion array de unos para guardar el numero de stimadores\n",
        "\n",
        "modelo=dict()\n",
        "j=0\n",
        "for i in range(1,10):\n",
        "    models['model'+str(i)] = Sequential() #Inicialización del modelo\n",
        "    models['model'+str(i)].add(Conv1D(filters=4, kernel_size=3, activation='relu', input_shape=(885,1)))# Capa convolucional con 32 filtros y tamaño del kernel 3\n",
        "    models['model'+str(i)].add(Conv1D(filters=32, kernel_size=3, activation='relu'))# Capa convolucional con 32 filtros y tamaño del kernel 3\n",
        "    models['model'+str(i)].add(Dropout(0.5)) #Dropout de 50%\n",
        "    models['model'+str(i)].add(MaxPooling1D(pool_size=2)) # Capa poolig de tamaño 2\n",
        "    models['model'+str(i)].add(Flatten()) # Capa Flatten\n",
        "    #parte totalmente conectada\n",
        "    models['model'+str(i)].add(Dense(1000, activation='relu',activity_regularizer=l1(i*0.0003))) # Capa con 1000 neuronas\n",
        "    models['model'+str(i)].add(Dense(500, activation='relu',activity_regularizer=l1(i*0.0003)))  #\n",
        "\n",
        "\n",
        "    models['model'+str(i)].add(Dense(4, activation='softmax',activity_regularizer=l1(i*0.0001)))\n",
        "    adam =optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, amsgrad= True) #Inicializar optimizador:Adam\n",
        "    models['model'+str(i)].compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', 'mse']) # Compilar modelo\n",
        "    modelo['modelo'+str(i)]=models['model'+str(i)].fit(x=X, y=Y, epochs=15,class_weight=class_weights,validation_data=(X_val, Y_val))\n",
        "    datos = models['model'+str(i)].evaluate(X_val, Y_val, verbose=0)\n",
        "    accuracys[j] =datos[1]*100\n",
        "    graficax[j]=i\n",
        "    j=j+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "08ba5bcf-9a78-4bb5-f366-c0d6fa8159e4",
        "id": "NKEhMBZrdarv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#encontrar el modelo con el mejor accuracy\n",
        "value2=np.max(accuracys)\n",
        "i2= np.where(accuracys == value2)\n",
        "\n",
        "maximo_x=graficax[i2[0][0]]\n",
        "\n",
        "print(\"Mejor modelo en los datos de validación ,usando \"+str(float(maximo_x*0.0001))+\" como parametro de regularización, con un valor  de:\"+str(value2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor modelo en los datos de validación ,usando 0.0003 como parametro de regularización, con un valor  de:69.91279034219922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-adfdDBWduj"
      },
      "source": [
        "Se obtuvo que el parametro se regularización adecuado es 0.0003 en la parte totalmente conectada. Se deja este modelo como el final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXj8XWHggpBd"
      },
      "source": [
        "Adiconal, se menciona que se probaron diferentes optimizadores con varias tasas de aprendizaje pero ninguno supero a lo obtenido con ADAM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XODOlRz8gpY8"
      },
      "source": [
        "Se vuelve a entrenar el modelo final con el fin de evaluar su comportamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5IxWdg-WHsf"
      },
      "source": [
        "model = Sequential() #Inicialización del modelo\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(885,1)))# Capa convolucional con 32 filtros y tamaño del kernel 3\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))# Capa convolucional con 32 filtros y tamaño del kernel 3\n",
        "model.add(Dropout(0.5)) #Dropout de 50%\n",
        "model.add(MaxPooling1D(pool_size=2)) # Capa poolig de tamaño 2\n",
        "model.add(Flatten()) # Capa Flatten\n",
        "#parte totalmente conectada\n",
        "model.add(Dense(1000, activation='relu',activity_regularizer=l1(0.0003))) # Capa con 1000 neuronas\n",
        "model.add(Dense(500, activation='relu',activity_regularizer=l1(0.0003)))  #\n",
        "model.add(Dense(4, activation='softmax',activity_regularizer=l1(0.0003))) #Capa de salida con función de activació\n",
        "\n",
        "\n",
        "adam =optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, amsgrad= True) #Inicializar optimizador:Adam\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['acc', 'mse']) # Compilar modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvGvS3zOSmf5"
      },
      "source": [
        "##modelo construido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EovBdKVqSpB2"
      },
      "source": [
        "El modelo final tiene la siguiente estructura:\n",
        "\n",
        "\n",
        "\n",
        "1.  Capa convolucional 1D: 32 filtros, tamaño del kernel=3, función de activación Relu\n",
        "2. Capa convolucional 1D: 32 filtros, tamaño del kernel=3, función de activación Relu\n",
        "3. Capa Dropout: 50%, aleatoriamente se seleccionan neuronas que no se tendran en cuenta en cada capa.\n",
        "4. Capa Pooling 1D con tamaño 2: Se utiliza para reducir la dimesionalidad de los datos y mejorar los tiempos de entrenamiento.\n",
        "5. Capa Flatten: Se ajustan los datos a un solo vector para su correcto funcionamiento en la capa totalmente conectada.\n",
        "6. Capa totalmente conectada: 1000 neuronas, función de activación Relu y regularización l1 de 0.0003\n",
        "7. Capa totalmente conectada: 500 neuronas, función de activación Relu y regularización l1 de 0.0003\n",
        "8. Capa totalmente conectada: 4 neuronas, función de activación softmax y regularización l1 de 0.0003\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUUF829icFyv",
        "outputId": "e2e4410b-1edc-4a1a-9c73-a4cc64406f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary() #resumen del modelo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_17 (Conv1D)           (None, 883, 32)           128       \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 881, 32)           3104      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 881, 32)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_9 (MaxPooling1 (None, 440, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 14080)             0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1000)              14081000  \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 4)                 2004      \n",
            "=================================================================\n",
            "Total params: 14,586,736\n",
            "Trainable params: 14,586,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1DgYKo-9stW",
        "outputId": "9cb122ad-2b72-4024-a1f8-06de2763c361",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "modelo=model.fit(x=X, y=Y, epochs=30,class_weight=class_weights,validation_data=(X_val, Y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 89402 samples, validate on 11170 samples\n",
            "Epoch 1/30\n",
            "89402/89402 [==============================] - 33s 371us/step - loss: 1.3745 - acc: 0.5371 - mean_squared_error: 0.1714 - val_loss: 1.3637 - val_acc: 0.4479 - val_mean_squared_error: 0.1753\n",
            "Epoch 2/30\n",
            "89402/89402 [==============================] - 31s 351us/step - loss: 1.2401 - acc: 0.5373 - mean_squared_error: 0.1539 - val_loss: 1.3271 - val_acc: 0.4479 - val_mean_squared_error: 0.1723\n",
            "Epoch 3/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 1.2076 - acc: 0.5377 - mean_squared_error: 0.1505 - val_loss: 1.3005 - val_acc: 0.4485 - val_mean_squared_error: 0.1696\n",
            "Epoch 4/30\n",
            "89402/89402 [==============================] - 31s 351us/step - loss: 1.1544 - acc: 0.5848 - mean_squared_error: 0.1423 - val_loss: 1.2449 - val_acc: 0.4916 - val_mean_squared_error: 0.1606\n",
            "Epoch 5/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 1.1133 - acc: 0.5934 - mean_squared_error: 0.1372 - val_loss: 1.2052 - val_acc: 0.4925 - val_mean_squared_error: 0.1559\n",
            "Epoch 6/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 1.0875 - acc: 0.5968 - mean_squared_error: 0.1346 - val_loss: 1.1856 - val_acc: 0.4890 - val_mean_squared_error: 0.1542\n",
            "Epoch 7/30\n",
            "89402/89402 [==============================] - 32s 353us/step - loss: 1.0685 - acc: 0.5981 - mean_squared_error: 0.1328 - val_loss: 1.1638 - val_acc: 0.4929 - val_mean_squared_error: 0.1517\n",
            "Epoch 8/30\n",
            "89402/89402 [==============================] - 31s 351us/step - loss: 1.0524 - acc: 0.5984 - mean_squared_error: 0.1311 - val_loss: 1.1517 - val_acc: 0.4934 - val_mean_squared_error: 0.1507\n",
            "Epoch 9/30\n",
            "89402/89402 [==============================] - 31s 349us/step - loss: 1.0394 - acc: 0.5992 - mean_squared_error: 0.1299 - val_loss: 1.1378 - val_acc: 0.4967 - val_mean_squared_error: 0.1492\n",
            "Epoch 10/30\n",
            "89402/89402 [==============================] - 31s 351us/step - loss: 1.0260 - acc: 0.6011 - mean_squared_error: 0.1285 - val_loss: 1.1232 - val_acc: 0.4995 - val_mean_squared_error: 0.1473\n",
            "Epoch 11/30\n",
            "89402/89402 [==============================] - 32s 354us/step - loss: 1.0147 - acc: 0.6008 - mean_squared_error: 0.1271 - val_loss: 1.1075 - val_acc: 0.5084 - val_mean_squared_error: 0.1453\n",
            "Epoch 12/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 0.9965 - acc: 0.6122 - mean_squared_error: 0.1243 - val_loss: 1.0814 - val_acc: 0.5342 - val_mean_squared_error: 0.1411\n",
            "Epoch 13/30\n",
            "89402/89402 [==============================] - 31s 349us/step - loss: 0.9800 - acc: 0.6198 - mean_squared_error: 0.1219 - val_loss: 1.0677 - val_acc: 0.5695 - val_mean_squared_error: 0.1391\n",
            "Epoch 14/30\n",
            "89402/89402 [==============================] - 31s 349us/step - loss: 0.9662 - acc: 0.6291 - mean_squared_error: 0.1199 - val_loss: 1.0483 - val_acc: 0.5927 - val_mean_squared_error: 0.1361\n",
            "Epoch 15/30\n",
            "89402/89402 [==============================] - 31s 348us/step - loss: 0.9534 - acc: 0.6351 - mean_squared_error: 0.1181 - val_loss: 1.0328 - val_acc: 0.6087 - val_mean_squared_error: 0.1336\n",
            "Epoch 16/30\n",
            "89402/89402 [==============================] - 31s 348us/step - loss: 0.9412 - acc: 0.6413 - mean_squared_error: 0.1163 - val_loss: 1.0136 - val_acc: 0.6175 - val_mean_squared_error: 0.1302\n",
            "Epoch 17/30\n",
            "89402/89402 [==============================] - 31s 352us/step - loss: 0.9302 - acc: 0.6468 - mean_squared_error: 0.1146 - val_loss: 0.9958 - val_acc: 0.6294 - val_mean_squared_error: 0.1271\n",
            "Epoch 18/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 0.9171 - acc: 0.6520 - mean_squared_error: 0.1126 - val_loss: 0.9817 - val_acc: 0.6350 - val_mean_squared_error: 0.1246\n",
            "Epoch 19/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 0.9059 - acc: 0.6553 - mean_squared_error: 0.1109 - val_loss: 0.9676 - val_acc: 0.6411 - val_mean_squared_error: 0.1223\n",
            "Epoch 20/30\n",
            "89402/89402 [==============================] - 31s 351us/step - loss: 0.8942 - acc: 0.6585 - mean_squared_error: 0.1092 - val_loss: 0.9509 - val_acc: 0.6455 - val_mean_squared_error: 0.1194\n",
            "Epoch 21/30\n",
            "89402/89402 [==============================] - 31s 352us/step - loss: 0.8849 - acc: 0.6607 - mean_squared_error: 0.1078 - val_loss: 0.9391 - val_acc: 0.6508 - val_mean_squared_error: 0.1175\n",
            "Epoch 22/30\n",
            "89402/89402 [==============================] - 31s 351us/step - loss: 0.8747 - acc: 0.6631 - mean_squared_error: 0.1064 - val_loss: 0.9272 - val_acc: 0.6546 - val_mean_squared_error: 0.1156\n",
            "Epoch 23/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 0.8673 - acc: 0.6646 - mean_squared_error: 0.1054 - val_loss: 0.9178 - val_acc: 0.6567 - val_mean_squared_error: 0.1143\n",
            "Epoch 24/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 0.8582 - acc: 0.6664 - mean_squared_error: 0.1042 - val_loss: 0.9147 - val_acc: 0.6561 - val_mean_squared_error: 0.1136\n",
            "Epoch 25/30\n",
            "89402/89402 [==============================] - 31s 350us/step - loss: 0.8524 - acc: 0.6675 - mean_squared_error: 0.1034 - val_loss: 0.9050 - val_acc: 0.6597 - val_mean_squared_error: 0.1123\n",
            "Epoch 26/30\n",
            "89402/89402 [==============================] - 31s 349us/step - loss: 0.8463 - acc: 0.6683 - mean_squared_error: 0.1027 - val_loss: 0.8983 - val_acc: 0.6627 - val_mean_squared_error: 0.1112\n",
            "Epoch 27/30\n",
            "89402/89402 [==============================] - 31s 352us/step - loss: 0.8395 - acc: 0.6860 - mean_squared_error: 0.1018 - val_loss: 0.8929 - val_acc: 0.6898 - val_mean_squared_error: 0.1106\n",
            "Epoch 28/30\n",
            "89402/89402 [==============================] - 31s 351us/step - loss: 0.8356 - acc: 0.7035 - mean_squared_error: 0.1014 - val_loss: 0.8882 - val_acc: 0.6982 - val_mean_squared_error: 0.1100\n",
            "Epoch 29/30\n",
            "89402/89402 [==============================] - 31s 351us/step - loss: 0.8297 - acc: 0.7070 - mean_squared_error: 0.1006 - val_loss: 0.8815 - val_acc: 0.7056 - val_mean_squared_error: 0.1090\n",
            "Epoch 30/30\n",
            "89402/89402 [==============================] - 31s 352us/step - loss: 0.8236 - acc: 0.7135 - mean_squared_error: 0.0998 - val_loss: 0.8768 - val_acc: 0.7088 - val_mean_squared_error: 0.1083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1z84MxQaNIw"
      },
      "source": [
        "Se evidencia que el modelo es entranado adecuadamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8q0l3sZagfA",
        "outputId": "0bffdbc0-6c3a-4239-b94c-183bb66d5a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(modelo.history['acc'])\n",
        "plt.plot(modelo.history['val_acc'])\n",
        "plt.title('accuracy de modelo')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Época')\n",
        "plt.legend(['Entranamiento', 'Validación'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEYCAYAAACp5wpbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mUnnmxHeXnr"
      },
      "source": [
        "El accuracy en los datos de validación es 70.88%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAVSLpoyandd"
      },
      "source": [
        "Finalmente, se evaluca el modelo en los datos de test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUJBsQe24y_T",
        "outputId": "cc2d4f49-bfde-4b5b-83aa-628b40b95edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "datos = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"accuracy en los datos de test: \"+ str(datos[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy en los datos de test: 68.82826475636477\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}